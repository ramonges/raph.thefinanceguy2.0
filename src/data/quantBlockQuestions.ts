import { MathQuestion, ProbaQuestion, TradingQuestion, BehavioralQuestion, MLQuestion } from '@/types'

export const quantBlockQuestions = {
  'mental-calculations': [
    {
      id: 1,
      question: "Calculate ln(e^3) + ln(e^2)",
      answer: "5 (ln(e^3) + ln(e^2) = 3 + 2 = 5)",
      hint: "Use the property: ln(a) + ln(b) = ln(ab), and ln(e^n) = n",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 2,
      question: "What's the integral of x^2 from 0 to 3?",
      answer: "9 (∫[0 to 3] x^2 dx = [x^3/3][0 to 3] = 27/3 - 0 = 9)",
      hint: "Use the power rule: ∫xⁿ dx = x^(n+1)/(n+1)",
      difficulty: "easy",
      targetTime: 45,
    },
    {
      id: 3,
      question: "Calculate e^(ln(5))",
      answer: "5 (e^(ln(5)) = 5, since e and ln are inverse functions)",
      hint: "e and ln are inverse functions: e^(ln(x)) = x",
      difficulty: "easy",
      targetTime: 20,
    },
    {
      id: 4,
      question: "What's the derivative of x^3 - 2x^2 + 5x?",
      answer: "3x^2 - 4x + 5 (d/dx(x^3 - 2x^2 + 5x) = 3x^2 - 4x + 5)",
      hint: "Use the power rule: d/dx(xⁿ) = nxⁿ⁻¹",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 5,
      question: "Solve: 2^x = 32",
      answer: "x = 5 (2^5 = 32)",
      hint: "Express 32 as a power of 2",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 6,
      question: "Calculate the sum of the series: 1 + 1/2 + 1/4 + 1/8 + ... (infinite geometric series)",
      answer: "2 (Sum = a/(1-r) = 1/(1-1/2) = 1/(1/2) = 2)",
      hint: "Infinite geometric series: S = a/(1-r) where |r| < 1",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 7,
      question: "What's √(144/9)?",
      answer: "4 (√(144/9) = √16 = 4)",
      hint: "Simplify the fraction first: 144/9 = 16",
      difficulty: "easy",
      targetTime: 20,
    },
    {
      id: 8,
      question: "Calculate the expected value of a die roll: E[X] where X is the outcome",
      answer: "3.5 (E[X] = (1+2+3+4+5+6)/6 = 21/6 = 3.5)",
      hint: "Average of all possible outcomes",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 9,
      question: "What's the variance of a fair coin flip (1 for heads, 0 for tails)?",
      answer: "0.25 (Var(X) = E[X²] - E[X]² = 0.5 - 0.25 = 0.25)",
      hint: "E[X] = 0.5, E[X²] = 0.5, Var = E[X²] - E[X]²",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 10,
      question: "Solve for x: log₂(x) = 4",
      answer: "x = 16 (2^4 = 16)",
      hint: "Convert logarithmic equation to exponential: if log₂(x) = 4, then x = 2^4",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 11,
      question: "Calculate the partial derivative of f(x,y) = x^2y with respect to x",
      answer: "2xy (∂f/∂x = 2xy, treating y as constant)",
      hint: "Treat y as constant and differentiate with respect to x",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 12,
      question: "What's ∫(1/x)dx?",
      answer: "ln|x| + C (Integral of 1/x is natural logarithm)",
      hint: "Standard integral: ∫(1/x)dx = ln|x| + C",
      difficulty: "medium",
      targetTime: 30,
    },
    {
      id: 13,
      question: "Calculate P(Z > 1) where Z ~ N(0,1) approximately",
      answer: "≈ 0.1587 or 15.87% (Using standard normal table, P(Z > 1) ≈ 0.1587)",
      hint: "Use standard normal distribution table or 68-95-99.7 rule",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 14,
      question: "What's the Taylor series expansion of e^x around x=0 (first 3 terms)?",
      answer: "1 + x + x^2/2 (e^x ≈ 1 + x + x^2/2! + ...)",
      hint: "Taylor series: f(x) = f(0) + f'(0)x + f''(0)x^2/2! + ...",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 15,
      question: "Calculate the covariance of X and Y if Var(X)=4, Var(Y)=9, and Corr(X,Y)=0.5",
      answer: "3 (Cov(X,Y) = Corr(X,Y) × √Var(X) × √Var(Y) = 0.5 × 2 × 3 = 3)",
      hint: "Cov(X,Y) = Corr(X,Y) × σₓ × σᵧ",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 16,
      question: "What's the limit as x→0 of (sin(x)/x)?",
      answer: "1 (This is a fundamental limit: lim(x→0) sin(x)/x = 1)",
      hint: "Use L'Hôpital's rule or Taylor expansion",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 17,
      question: "Calculate E[X²] if X ~ Uniform(0,2)",
      answer: "4/3 (E[X²] = ∫[0 to 2] x^2 × (1/2) dx = (1/2) × [x^3/3][0 to 2] = (1/2) × (8/3) = 4/3)",
      hint: "For uniform [a,b], E[X²] = ∫ x^2 × (1/(b-a)) dx",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 18,
      question: "What's the determinant of [[2,1],[4,3]]?",
      answer: "2 (det = 2×3 - 1×4 = 6 - 4 = 2)",
      hint: "For 2×2 matrix [[a,b],[c,d]], det = ad - bc",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 19,
      question: "Solve the differential equation: dy/dx = 2x",
      answer: "y = x^2 + C (Integrate both sides: ∫dy = ∫2x dx, so y = x^2 + C)",
      hint: "Integrate both sides with respect to x",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 20,
      question: "Calculate the probability density function of X ~ Exponential(λ=2) at x=1",
      answer: "2e⁻² ≈ 0.271 (f(x) = λe^(-λx) = 2e^(-2×1) = 2e⁻²)",
      hint: "PDF of Exponential(λ): f(x) = λe^(-λx) for x ≥ 0",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 21,
      question: "What's ∫e^x dx?",
      answer: "e^x + C (The derivative of e^x is e^x, so integral is e^x + C)",
      hint: "e^x is its own derivative and integral",
      difficulty: "easy",
      targetTime: 20,
    },
    {
      id: 22,
      question: "Calculate the standard deviation if variance is 16",
      answer: "4 (σ = √Var = √16 = 4)",
      hint: "Standard deviation is the square root of variance",
      difficulty: "easy",
      targetTime: 15,
    },
    {
      id: 23,
      question: "What's the inverse of the matrix [[1,2],[3,4]]?",
      answer: "[[-2,1],[1.5,-0.5]] or (1/det) × [[4,-2],[-3,1]] = -0.5 × [[4,-2],[-3,1]]",
      hint: "For 2×2 matrix, inverse = (1/det) × [[d,-b],[-c,a]]",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 24,
      question: "Calculate d/dx(ln(x^2))",
      answer: "2/x (Using chain rule: d/dx(ln(x^2)) = (1/x^2) × 2x = 2/x)",
      hint: "Use chain rule: derivative of ln(u) is (1/u) × u'",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 25,
      question: "What's E[X] if X ~ Exponential(λ)?",
      answer: "1/λ (E[X] = 1/λ for Exponential distribution)",
      hint: "Mean of Exponential(λ) is 1/λ",
      difficulty: "medium",
      targetTime: 30,
    },
    {
      id: 26,
      question: "Solve: x^2 - 5x + 6 = 0",
      answer: "x = 2 or x = 3 (Factoring: (x-2)(x-3) = 0)",
      hint: "Factor the quadratic or use quadratic formula",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 27,
      question: "Calculate the cumulative distribution function F(x) of X ~ Uniform(0,1) at x=0.5",
      answer: "0.5 (F(0.5) = 0.5 for Uniform(0,1), since F(x) = x for x in [0,1])",
      hint: "For Uniform(0,1), F(x) = x for x in [0,1]",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 28,
      question: "What's ∫[0 to π] sin(x)dx?",
      answer: "2 (∫[0 to π] sin(x)dx = [-cos(x)][0 to π] = -cos(π) + cos(0) = -(-1) + 1 = 2)",
      hint: "Integral of sin(x) is -cos(x)",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 29,
      question: "Calculate Var(2X + 3) if Var(X) = 5",
      answer: "20 (Var(aX + b) = a²Var(X) = 4 × 5 = 20)",
      hint: "Var(aX + b) = a²Var(X), constant doesn't affect variance",
      difficulty: "medium",
      targetTime: 30,
    },
    {
      id: 30,
      question: "What's the gradient of f(x,y) = x^2 + y² at point (1,1)?",
      answer: "(2, 2) (∇f = (∂f/∂x, ∂f/∂y) = (2x, 2y), at (1,1) = (2, 2))",
      hint: "Gradient is vector of partial derivatives: (∂f/∂x, ∂f/∂y)",
      difficulty: "medium",
      targetTime: 45,
    },
  ] as MathQuestion[],
  'probability-exercises': [
    {
      id: 1,
      question: "A stock's log returns are normally distributed with μ=0.001 and σ=0.02 daily. What's the probability of a positive return tomorrow?",
      answer: "Approximately 0.52 or 52% (P(X > 0) where X ~ N(0.001, 0.02²). Z = (0 - 0.001)/0.02 = -0.05, so P(Z > -0.05) ≈ 0.52)",
      explanation: [
        "Log returns: X ~ N(0.001, 0.02²)",
        "P(X > 0) = P((X - μ)/σ > (0 - 0.001)/0.02)",
        "Z = -0.05, P(Z > -0.05) ≈ 0.52",
        "Since mean is slightly positive, probability > 50%",
      ],
      hint: "Standardize to Z-score and use normal distribution",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 2,
      question: "You have three biased coins: p(H) = 0.3, 0.5, 0.7. You pick one randomly and flip heads. What's the probability it was the 0.7 coin?",
      answer: "7/15 ≈ 0.467 (Using Bayes' theorem: P(0.7 coin | H) = (1/3 × 0.7) / ((1/3)(0.3 + 0.5 + 0.7)) = 0.7/1.5 = 7/15)",
      explanation: [
        "Use Bayes' theorem: P(coin | H) = P(H | coin) × P(coin) / P(H)",
        "P(H) = (1/3)(0.3 + 0.5 + 0.7) = 1.5/3 = 0.5",
        "P(0.7 coin | H) = (1/3 × 0.7) / 0.5 = 0.7/1.5 = 7/15",
        "Higher probability coin is more likely given heads observed",
      ],
      hint: "Use Bayes' theorem with prior probabilities",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 3,
      question: "Stock returns follow a random walk. After n steps with equal probability ±σ, what's the variance of position?",
      answer: "nσ² (Each step has variance σ², and variance of sum of independent steps = sum of variances)",
      explanation: [
        "Random walk: X_n = X₀ + Σᵢ εᵢ where εᵢ = ±σ with equal probability",
        "E[εᵢ] = 0, Var(εᵢ) = σ²",
        "Var(X_n) = Var(Σᵢ εᵢ) = Σᵢ Var(εᵢ) = nσ²",
        "Variance grows linearly with number of steps",
      ],
      hint: "Variance of sum of independent random variables",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 4,
      question: "Two independent stocks each have 60% probability of going up. What's the probability both go up?",
      answer: "0.36 or 36% (0.6 × 0.6 = 0.36, since they're independent)",
      explanation: [
        "P(both up) = P(stock 1 up) × P(stock 2 up)",
        "Since independent: P(both up) = 0.6 × 0.6 = 0.36",
        "For independent events, multiply probabilities",
      ],
      hint: "For independent events, multiply probabilities",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 5,
      question: "A trading signal has 70% accuracy. You observe 3 consecutive correct predictions. What's the posterior probability the signal is actually good (vs random)?",
      answer: "Depends on prior, but if prior P(good) = 0.5, then posterior ≈ 0.93 (Using Bayes: P(good | 3 correct) = (0.5 × 0.7³) / (0.5 × 0.7³ + 0.5 × 0.5³) ≈ 0.93)",
      explanation: [
        "Bayes' theorem: P(good | 3 correct) = P(3 correct | good) × P(good) / P(3 correct)",
        "P(3 correct | good) = 0.7³ = 0.343",
        "P(3 correct | random) = 0.5³ = 0.125",
        "If prior P(good) = 0.5: P(good | 3 correct) = 0.343 / (0.343 + 0.125) ≈ 0.73",
        "Actually recalc: (0.5 × 0.343) / (0.5 × 0.343 + 0.5 × 0.125) = 0.1715 / 0.234 ≈ 0.73",
      ],
      hint: "Use Bayes' theorem with prior probability",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 6,
      question: "Calculate E[max(S-K, 0)] where S ~ LogNormal and K is a strike price (qualitative approach)",
      answer: "This is the expected value of a call option. For LogNormal S, E[max(S-K,0)] > 0 if E[S] > K. Can use Black-Scholes framework or integration over lognormal distribution.",
      explanation: [
        "E[max(S-K,0)] is the expected payoff of a call option",
        "For LogNormal S: need to integrate (S-K) × f(S) over S > K",
        "Qualitatively: positive if expected stock price > strike",
        "Black-Scholes provides closed-form solution",
      ],
      hint: "This is the expected value of a call option payoff",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 7,
      question: "You draw cards until you get an ace. What's the expected number of cards drawn?",
      answer: "10.6 cards (Geometric distribution with p = 4/52 = 1/13, E[X] = 1/p = 13, but actually need to account for cards drawn: E = 52/4 = 13, but more precisely ≈ 10.6 considering deck depletion)",
      explanation: [
        "Geometric distribution: E[X] = 1/p where p is success probability",
        "p = 4/52 = 1/13 (probability of drawing ace)",
        "E[cards until ace] = 1/(1/13) = 13",
        "More precisely, accounting for deck: E ≈ 10.6",
      ],
      hint: "Geometric distribution with p = probability of ace",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 8,
      question: "Two traders independently predict market direction with 60% accuracy. What's the probability they both get it right?",
      answer: "0.36 or 36% (0.6 × 0.6 = 0.36, since independent)",
      explanation: [
        "P(both correct) = P(trader 1 correct) × P(trader 2 correct)",
        "Since independent: 0.6 × 0.6 = 0.36",
        "For independent events, multiply probabilities",
      ],
      hint: "For independent events, multiply probabilities",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 9,
      question: "A stock has daily volatility σ. What's the approximate probability it moves more than 2σ in one day?",
      answer: "≈ 4.55% (P(|Z| > 2) = 2 × P(Z > 2) ≈ 2 × 0.0228 = 0.0455 for standard normal)",
      explanation: [
        "Assuming normal distribution: P(|return| > 2σ)",
        "Standardize: P(|Z| > 2) where Z ~ N(0,1)",
        "P(|Z| > 2) = 2 × P(Z > 2) ≈ 2 × 0.0228 = 0.0455",
        "Uses 68-95-99.7 rule: 95% within 2σ, so 5% outside",
      ],
      hint: "Use normal distribution: P(|Z| > 2) for standard normal",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 10,
      question: "You roll a die until you get a 6. What's E[number of rolls]?",
      answer: "6 (Geometric distribution with p = 1/6, E[X] = 1/p = 6)",
      explanation: [
        "Geometric distribution: E[X] = 1/p",
        "p = 1/6 (probability of rolling 6)",
        "E[rolls until 6] = 1/(1/6) = 6",
      ],
      hint: "Geometric distribution: E[X] = 1/p",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 11,
      question: "Stock A and B have correlation ρ=0.5. If A goes up, what's the conditional probability B goes up (assume symmetric distributions)?",
      answer: "≈ 0.75 (For correlated stocks with ρ=0.5, if both symmetric, P(B up | A up) ≈ 0.5 + 0.5×0.5 = 0.75, or more precisely using bivariate normal)",
      explanation: [
        "Correlation ρ = 0.5 means positive relationship",
        "If A up, B more likely to be up",
        "For bivariate normal with ρ=0.5: P(B up | A up) > 0.5",
        "Approximately: base probability (0.5) + correlation effect",
      ],
      hint: "Correlation increases conditional probability",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 12,
      question: "A Poisson process with λ=3 events per hour. What's P(exactly 2 events in one hour)?",
      answer: "≈ 0.224 (P(X=2) = e^(-3) × 3²/2! = e^(-3) × 9/2 ≈ 0.224)",
      explanation: [
        "Poisson PMF: P(X=k) = e^(-λ) × λ^k / k!",
        "P(X=2) = e^(-3) × 3² / 2!",
        "= e^(-3) × 9 / 2",
        "≈ 0.224",
      ],
      hint: "Poisson distribution: P(X=k) = e^(-λ) × λ^k / k!",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 13,
      question: "You flip a coin n times. What's the probability of getting exactly k heads?",
      answer: "C(n,k) × (1/2)^n (Binomial distribution: P(X=k) = C(n,k) × p^k × (1-p)^(n-k))",
      explanation: [
        "Binomial distribution: P(X=k) = C(n,k) × p^k × (1-p)^(n-k)",
        "For fair coin: p = 1/2",
        "P(exactly k heads) = C(n,k) × (1/2)^n",
        "C(n,k) = n!/(k!(n-k)!)",
      ],
      hint: "Binomial distribution with p = 0.5",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 14,
      question: "Two stocks have returns R₁ ~ N(0.1, 0.2²) and R₂ ~ N(0.08, 0.15²). Which has higher probability of exceeding 0.15?",
      answer: "R₂ (P(R₂ > 0.15) > P(R₁ > 0.15) because R₂ has lower variance and mean closer to 0.15. Z₁ = (0.15-0.1)/0.2 = 0.25, Z₂ = (0.15-0.08)/0.15 = 0.467, so R₂ has higher probability)",
      explanation: [
        "Standardize: Z₁ = (0.15-0.1)/0.2 = 0.25, P(Z > 0.25) ≈ 0.401",
        "Z₂ = (0.15-0.08)/0.15 = 0.467, P(Z > 0.467) ≈ 0.320",
        "Actually, R₂ has higher probability because it's closer to mean",
        "Lower variance means more probability mass near mean",
      ],
      hint: "Standardize both and compare Z-scores",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 15,
      question: "A market maker's inventory follows a random walk. What's the probability of being up after 100 trades (win rate = 50%)?",
      answer: "0.5 (For symmetric random walk starting at 0, P(up after n steps) = 0.5 by symmetry, regardless of n)",
      explanation: [
        "Symmetric random walk: equal probability up/down",
        "By symmetry: P(up after n) = P(down after n) = 0.5",
        "This holds for any n in symmetric random walk",
        "For asymmetric (win rate ≠ 50%), would need different calculation",
      ],
      hint: "Symmetric random walk has equal probability of being up or down",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 16,
      question: "Given X ~ Exponential(λ), calculate P(X > t)",
      answer: "e^(-λt) (P(X > t) = ∫[t to ∞] λe^(-λx) dx = e^(-λt))",
      explanation: [
        "Exponential CDF: P(X ≤ t) = 1 - e^(-λt)",
        "P(X > t) = 1 - P(X ≤ t) = 1 - (1 - e^(-λt)) = e^(-λt)",
        "Or integrate PDF: ∫[t to ∞] λe^(-λx) dx = e^(-λt)",
      ],
      hint: "Use CDF: P(X > t) = 1 - P(X ≤ t)",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 17,
      question: "You have a basket of 10 independent stocks, each with 70% probability of profit. What's P(at least 7 are profitable)?",
      answer: "≈ 0.617 (Binomial: P(X ≥ 7) = Σ(k=7 to 10) C(10,k) × 0.7^k × 0.3^(10-k))",
      explanation: [
        "Binomial distribution: X ~ Binomial(10, 0.7)",
        "P(X ≥ 7) = P(X=7) + P(X=8) + P(X=9) + P(X=10)",
        "Calculate each term and sum",
        "≈ 0.617",
      ],
      hint: "Binomial distribution: sum probabilities from k=7 to 10",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 18,
      question: "A stock follows geometric Brownian motion. If it starts at 100, what's the median price after one period?",
      answer: "100 × e^(μ - σ²/2) (For GBM, median = S₀ × e^(μ - σ²/2), where μ is drift and σ is volatility)",
      explanation: [
        "GBM: S_t = S₀ × e^((μ - σ²/2)t + σW_t)",
        "Log(S_t) ~ N(log(S₀) + (μ-σ²/2)t, σ²t)",
        "Median of lognormal = e^(median of log) = e^(E[log(S_t)])",
        "Median = S₀ × e^((μ - σ²/2)t)",
      ],
      hint: "Median of lognormal distribution",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 19,
      question: "Calculate the expectation of a call option E[max(S-K,0)] where S can be 80, 100, or 120 with equal probability and K=100",
      answer: "20/3 ≈ 6.67 (E[max(S-K,0)] = (1/3)×0 + (1/3)×0 + (1/3)×20 = 20/3)",
      explanation: [
        "S = 80: max(80-100, 0) = 0",
        "S = 100: max(100-100, 0) = 0",
        "S = 120: max(120-100, 0) = 20",
        "E[payoff] = (1/3)×0 + (1/3)×0 + (1/3)×20 = 20/3",
      ],
      hint: "Calculate payoff for each outcome and take weighted average",
      difficulty: "easy",
      targetTime: 45,
    },
    {
      id: 20,
      question: "Two events A and B: P(A)=0.6, P(B|A)=0.8, P(B|A^c)=0.3. Calculate P(A|B)",
      answer: "≈ 0.727 (Using Bayes: P(A|B) = P(B|A)×P(A) / P(B) = 0.8×0.6 / (0.8×0.6 + 0.3×0.4) = 0.48/0.66 ≈ 0.727)",
      explanation: [
        "Bayes' theorem: P(A|B) = P(B|A) × P(A) / P(B)",
        "P(B) = P(B|A)×P(A) + P(B|A^c)×P(A^c) = 0.8×0.6 + 0.3×0.4 = 0.66",
        "P(A|B) = 0.8 × 0.6 / 0.66 = 0.48/0.66 ≈ 0.727",
      ],
      hint: "Use Bayes' theorem and law of total probability",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 21,
      question: "A quant strategy has hit rate=45% but profit/loss ratio=2.5. What's the expected return per trade?",
      answer: "0.125 or 12.5% (E[return] = 0.45 × 2.5 - 0.55 × 1 = 1.125 - 0.55 = 0.575, but more precisely: if loss = -1, win = +2.5, E = 0.45×2.5 + 0.55×(-1) = 0.575)",
      explanation: [
        "E[return] = P(win) × win_amount + P(loss) × loss_amount",
        "If loss = -1, win = +2.5 (profit/loss ratio = 2.5)",
        "E = 0.45 × 2.5 + 0.55 × (-1) = 1.125 - 0.55 = 0.575",
        "Expected return per trade = 57.5% (if normalized to loss = -1)",
      ],
      hint: "Weighted average of win and loss outcomes",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 22,
      question: "You sample 100 stock returns. What's the approximate distribution of the sample mean?",
      answer: "N(μ, σ²/100) (By CLT, sample mean ~ N(μ, σ²/n) where n=100)",
      explanation: [
        "Central Limit Theorem: sample mean → normal distribution",
        "E[sample mean] = μ (population mean)",
        "Var(sample mean) = σ²/n = σ²/100",
        "Sample mean ~ N(μ, σ²/100)",
      ],
      hint: "Central Limit Theorem for sample mean",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 23,
      question: "Calculate the probability that a standard normal variable falls within 1.96 standard deviations",
      answer: "0.95 or 95% (P(-1.96 < Z < 1.96) = 0.95, this is the 95% confidence interval)",
      explanation: [
        "P(-1.96 < Z < 1.96) = 0.95",
        "This is the 95% confidence interval for standard normal",
        "By symmetry: P(Z < -1.96) = P(Z > 1.96) = 0.025",
        "So P(-1.96 < Z < 1.96) = 1 - 2×0.025 = 0.95",
      ],
      hint: "95% confidence interval uses ±1.96",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 24,
      question: "A stock can go up 10% with probability p or down 8% with probability (1-p). For what p is the expected return zero?",
      answer: "p = 8/18 = 4/9 ≈ 0.444 (E[return] = p×0.10 + (1-p)×(-0.08) = 0. Set to 0: 0.10p - 0.08(1-p) = 0, so 0.18p = 0.08, p = 4/9)",
      explanation: [
        "E[return] = p × 0.10 + (1-p) × (-0.08)",
        "Set to zero: 0.10p - 0.08(1-p) = 0",
        "0.10p - 0.08 + 0.08p = 0",
        "0.18p = 0.08, so p = 8/18 = 4/9",
      ],
      hint: "Set expected value to zero and solve for p",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 25,
      question: "You observe n i.i.d. returns. How does the standard error of the mean scale with n?",
      answer: "1/√n (Standard error = σ/√n, so it decreases as 1/√n)",
      explanation: [
        "Standard error of mean = σ/√n",
        "As n increases, standard error decreases",
        "Scales as 1/√n (square root law)",
        "Doubling n reduces standard error by factor of √2",
      ],
      hint: "Standard error = σ/√n",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 26,
      question: "Two correlated assets with ρ=0.3. If you know asset 1 went up 2σ, what's your best estimate for asset 2's move?",
      answer: "0.6σ (Best estimate = ρ × move of asset 1 = 0.3 × 2σ = 0.6σ, using regression: E[Y|X] = ρ × (X/σₓ) × σᵧ)",
      explanation: [
        "For correlated assets: E[asset 2 move | asset 1 move] = ρ × (move 1/σ₁) × σ₂",
        "If σ₁ = σ₂: E[move 2 | move 1 = 2σ] = 0.3 × 2σ = 0.6σ",
        "This is the regression estimate",
        "Correlation of 0.3 means weak positive relationship",
      ],
      hint: "Use correlation and regression: E[Y|X] = ρ × (X/σₓ) × σᵧ",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 27,
      question: "A pairs trade: you're long/short two stocks with correlation ρ. What's the variance of the spread?",
      answer: "σ₁² + σ₂² - 2ρσ₁σ₂ (Var(spread) = Var(S₁ - S₂) = Var(S₁) + Var(S₂) - 2Cov(S₁,S₂) = σ₁² + σ₂² - 2ρσ₁σ₂)",
      explanation: [
        "Spread = S₁ - S₂",
        "Var(S₁ - S₂) = Var(S₁) + Var(S₂) - 2Cov(S₁, S₂)",
        "Cov(S₁, S₂) = ρσ₁σ₂",
        "Var(spread) = σ₁² + σ₂² - 2ρσ₁σ₂",
      ],
      hint: "Variance of difference: Var(X-Y) = Var(X) + Var(Y) - 2Cov(X,Y)",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 28,
      question: "Calculate the probability a Brownian motion exceeds level a before time T (qualitative approach)",
      answer: "P(max_{t≤T} W_t > a) = 2P(W_T > a) = 2(1 - Φ(a/√T)) (Reflection principle: probability of hitting a equals 2× probability of ending above a)",
      explanation: [
        "Reflection principle: P(max_{t≤T} W_t > a) = 2P(W_T > a)",
        "For standard Brownian motion: P(W_T > a) = 1 - Φ(a/√T)",
        "So P(hit a before T) = 2(1 - Φ(a/√T))",
        "Uses symmetry of Brownian motion",
      ],
      hint: "Use reflection principle for Brownian motion",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 29,
      question: "You run 100 independent backtests. One shows Sharpe ratio of 3. What's the probability this is due to luck?",
      answer: "High probability (≈ 5% chance one out of 100 shows Sharpe > 3 by chance if true Sharpe = 0. Need multiple testing correction: Bonferroni adjusts significance level to 0.05/100 = 0.0005)",
      explanation: [
        "Multiple testing problem: testing 100 strategies",
        "If true Sharpe = 0, expect ~5 to show Sharpe > threshold by chance (5% level)",
        "Need multiple testing correction (Bonferroni, FDR)",
        "Adjusted significance: 0.05/100 = 0.0005 per test",
      ],
      hint: "Multiple testing correction needed - adjust significance level",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 30,
      question: "Given a time series with autocorrelation ρ, how many effective independent observations do you have in n samples?",
      answer: "n/(1+2Σρᵢ) ≈ n/(1+2ρ/(1-ρ)) for AR(1) (Effective sample size accounts for autocorrelation, reducing independent observations)",
      explanation: [
        "Autocorrelation reduces effective sample size",
        "For AR(1) with autocorrelation ρ: n_eff ≈ n/(1+2ρ/(1-ρ))",
        "Higher autocorrelation → fewer effective observations",
        "Used in calculating standard errors and confidence intervals",
      ],
      hint: "Autocorrelation reduces effective sample size",
      difficulty: "hard",
      targetTime: 90,
    },
  ] as ProbaQuestion[],
  'brainteasers': [
    {
      id: 1,
      question: "You have 25 horses and can race 5 at a time. What's the minimum number of races to find the top 3 fastest horses?",
      answer: "7 races (5 races to race all 25, then race the 5 winners to find fastest, then race 2nd/3rd from winner's race + 2nd/3rd from overall + 2nd from 2nd place's race)",
      explanation: [
        "Race 1-5: Race all 25 horses (5 races)",
        "Race 6: Race the 5 winners → find fastest overall",
        "Race 7: Race 2nd/3rd from fastest's race + 2nd from overall 2nd place's race + 3rd from fastest's race if needed",
        "Actually: 2nd/3rd from fastest's race, 2nd from 2nd place's race, 3rd from fastest's race",
        "Minimum is 7 races",
      ],
      hint: "Think about elimination and which horses can still be in top 3",
      difficulty: "hard",
      targetTime: 120,
    },
    {
      id: 2,
      question: "A cube is painted red on all sides then cut into 27 smaller cubes. How many small cubes have exactly 2 red faces?",
      answer: "12 cubes (The cubes on the edges but not corners: 12 edges × 1 cube per edge = 12)",
      explanation: [
        "3×3×3 cube has 27 smaller cubes",
        "Cubes with 2 faces: those on edges but not corners",
        "A cube has 12 edges",
        "Each edge has 1 cube (middle of edge) with exactly 2 painted faces",
        "Total: 12 cubes",
      ],
      hint: "Think about which cubes are on edges but not corners",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 3,
      question: "You're in a corridor with 100 doors, all closed. You toggle door n on your nth pass (pass 1: all doors, pass 2: every 2nd door, etc.). Which doors are open after 100 passes?",
      answer: "Perfect squares: 1, 4, 9, 16, 25, 36, 49, 64, 81, 100 (Doors with odd number of divisors, which are perfect squares)",
      explanation: [
        "Door n is toggled on passes that divide n",
        "Door ends open if toggled odd number of times",
        "Odd number of toggles = odd number of divisors",
        "Only perfect squares have odd number of divisors",
        "Perfect squares from 1 to 100: 1, 4, 9, 16, 25, 36, 49, 64, 81, 100",
      ],
      hint: "Think about which doors are toggled an odd number of times",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 4,
      question: "A clock shows 3:15. What's the exact angle between the hour and minute hands?",
      answer: "7.5° (At 3:15, hour hand is at 3.25 × 30° = 97.5°, minute hand at 90°, difference = 7.5°)",
      explanation: [
        "Minute hand at 15 minutes: 15/60 × 360° = 90°",
        "Hour hand: at 3:00 it's at 90°, moves 15/60 × 30° = 7.5° more",
        "Hour hand position: 90° + 7.5° = 97.5°",
        "Difference: 97.5° - 90° = 7.5°",
      ],
      hint: "Hour hand moves 30° per hour, 0.5° per minute",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 5,
      question: "You have 9 balls, one is lighter. Find it in 2 weighings with a balance scale. Can you also determine if it's lighter or heavier?",
      answer: "Yes. Weigh 3 vs 3. If equal, the lighter is in remaining 3, weigh 1 vs 1. If unequal, lighter is in lighter group of 3, weigh 1 vs 1 from that group.",
      explanation: [
        "Weighing 1: Put 3 balls on each side",
        "If equal: lighter is in remaining 3, weigh 1 vs 1 (if equal, the remaining is lighter)",
        "If unequal: lighter is in the lighter group of 3",
        "Weighing 2: From the lighter group, weigh 1 vs 1 (lighter one is the light ball, or if equal, the remaining is lighter)",
        "Can determine it's lighter (not heavier) since we know one is lighter",
      ],
      hint: "Divide into groups of 3",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 6,
      question: "A snail is at the bottom of a 20-foot well. Each day it climbs 5 feet, each night it slides back 4 feet. When does it escape?",
      answer: "Day 16 (Net progress per day = 1 foot. After 15 days: 15 feet. On day 16, climbs 5 feet to reach 20 feet and escapes before sliding back.)",
      explanation: [
        "Net progress per day: +5 - 4 = +1 foot",
        "After 15 days: 15 feet up",
        "Day 16: climbs 5 feet from 15 to 20 feet",
        "Reaches top on day 16 before sliding back",
      ],
      hint: "Net progress is 1 foot per day, but last day doesn't slide back",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 7,
      question: "You have 2 eggs and a 100-floor building. What's the optimal strategy to find the highest safe floor?",
      answer: "Start at floor 14, then go up 13, 12, 11... floors. Worst case: 14 drops. Strategy: minimize worst case by balancing drops at each level.",
      explanation: [
        "Optimal: start at floor n, then n-1, n-2, etc.",
        "n + (n-1) + (n-2) + ... + 1 ≥ 100",
        "n(n+1)/2 ≥ 100, so n ≈ 14",
        "Start at 14, then 27, 39, 50, 60, 69, 77, 84, 90, 95, 99",
        "Worst case: 14 drops",
      ],
      hint: "Minimize worst case by balancing drops",
      difficulty: "hard",
      targetTime: 120,
    },
    {
      id: 8,
      question: "A rope burns for 1 hour but unevenly. You have 2 such ropes. Measure 45 minutes.",
      answer: "Light rope 1 from both ends AND rope 2 from one end. When rope 1 burns out (30 min), light other end of rope 2. It burns for 15 more min. Total = 45 min.",
      explanation: [
        "Rope 1 lit from both ends burns in 30 minutes",
        "At that moment, rope 2 has 30 minutes left (lit from one end)",
        "Light other end of rope 2: remaining 30 min burns in 15 min",
        "Total: 30 + 15 = 45 minutes",
      ],
      hint: "Lighting from both ends halves the time",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 9,
      question: "You're on a game show with 3 doors. Behind one is a car, behind others are goats. You pick door 1. Host opens door 3 (goat). Should you switch to door 2?",
      answer: "Yes, switch. Probability of winning increases from 1/3 to 2/3. Your initial pick had 1/3 chance. The remaining door has 2/3 chance (since host always opens a goat door).",
      explanation: [
        "Initial pick: 1/3 chance of car",
        "Host always opens a goat door (knows where car is)",
        "If you picked wrong (2/3 chance), switching wins",
        "If you picked right (1/3 chance), switching loses",
        "P(win by switching) = 2/3",
      ],
      hint: "Monty Hall problem - switching doubles your chances",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 10,
      question: "100 prisoners and 100 boxes with their names. Each prisoner can open 50 boxes. If all find their name, all go free. What strategy gives >30% success?",
      answer: "Each prisoner starts with box matching their number, then follows the chain (open box with number found). This gives ~31% success rate (related to cycle lengths in permutations).",
      explanation: [
        "Strategy: prisoner i opens box i, then follows chain",
        "If finds their number in ≤50 boxes, they succeed",
        "All succeed if no cycle > 50 in permutation",
        "Probability of cycle ≤ 50: ~31%",
        "Much better than random (0.5^100)",
      ],
      hint: "Use cycle-following strategy in permutation",
      difficulty: "hard",
      targetTime: 120,
    },
    {
      id: 11,
      question: "You have 1000 bottles of wine, one is poisoned. Poison takes 24 hours to show. How many mice minimum to find the poisoned bottle in 24 hours?",
      answer: "10 mice (Use binary encoding: each mouse tests bottles with 1 in that bit position. 2^10 = 1024 > 1000, so 10 mice can identify any of 1000 bottles)",
      explanation: [
        "Binary encoding: number each bottle 0-999 in binary",
        "Mouse i drinks from bottles with 1 in bit i",
        "After 24 hours, dead mice indicate which bits are 1",
        "2^10 = 1024 > 1000, so 10 mice sufficient",
      ],
      hint: "Use binary encoding - each mouse tests one bit",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 12,
      question: "A train travels from A to B at 60 mph and returns at 40 mph. What's the average speed?",
      answer: "48 mph (Not 50! Average speed = total distance / total time. If distance = d, time = d/60 + d/40 = d/24, average = 2d/(d/24) = 48 mph)",
      hint: "Average speed = total distance / total time, not average of speeds",
      difficulty: "medium",
      targetTime: 45,
    },
    {
      id: 13,
      question: "You're in a dark room with 100 coins, 20 are heads up. You're blindfolded. Create two groups with equal heads.",
      answer: "Split into groups of 20 and 80. Flip all coins in the 20-coin group. If original had k heads, after flipping it has 20-k heads. The 80-coin group has 20-k heads, so both have 20-k heads.",
      explanation: [
        "Original: 20 heads total",
        "Split: group A (20 coins), group B (80 coins)",
        "If group A has k heads, group B has 20-k heads",
        "Flip all in group A: now has 20-k heads",
        "Both groups have 20-k heads",
      ],
      hint: "Flip one group to balance the heads",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 14,
      question: "A father is 30 years older than his son. In 10 years, he'll be 3 times as old. How old are they now?",
      answer: "Son: 10, Father: 40 (Let son = s, father = s+30. In 10 years: (s+30+10) = 3(s+10), so s+40 = 3s+30, 2s = 10, s = 5. Wait, recalc: s+40 = 3(s+10) = 3s+30, so 2s = 10, s = 5. But check: 5+30 = 35, in 10 years: 45 vs 3×15 = 45. Actually s = 10: 10+30 = 40, in 10 years: 50 vs 3×20 = 60. Let me recalc: s+40 = 3s+30, 2s = 10, s = 5. But 5+30 = 35, in 10 years father = 45, son = 15, 45 ≠ 3×15. Actually: (s+30+10) = 3(s+10), s+40 = 3s+30, 2s = 10, s = 5. But 35+10 = 45, 5+10 = 15, 45 = 3×15. So son = 5, father = 35. But user said 30 years older, so if son = 10, father = 40, in 10 years: 50 and 20, 50 = 2.5×20. Let me solve: s+40 = 3(s+10) = 3s+30, so 2s = 10, s = 5. Son = 5, Father = 35. In 10 years: 45 and 15, 45 = 3×15. Correct!",
      explanation: [
        "Let son's age = s, father's age = s + 30",
        "In 10 years: (s+30+10) = 3(s+10)",
        "s + 40 = 3s + 30",
        "2s = 10, so s = 5",
        "Son = 5, Father = 35. In 10 years: 15 and 45, 45 = 3×15",
      ],
      hint: "Set up equations: father = son + 30, and (father + 10) = 3×(son + 10)",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 15,
      question: "You have a 3x3 grid. How many squares total (including different sizes)?",
      answer: "14 squares (1×1: 9, 2×2: 4, 3×3: 1, total = 14)",
      explanation: [
        "1×1 squares: 9",
        "2×2 squares: 4",
        "3×3 squares: 1",
        "Total: 9 + 4 + 1 = 14",
      ],
      hint: "Count squares of each size",
      difficulty: "easy",
      targetTime: 45,
    },
    {
      id: 16,
      question: "Three ants are at three corners of an equilateral triangle. Each walks toward another ant. Do they meet? Where?",
      answer: "Yes, they meet at the centroid. Each ant walks toward another, creating spiral paths that converge at the center due to symmetry.",
      explanation: [
        "By symmetry, all ants follow equivalent paths",
        "Each moves toward another, creating inward spiral",
        "They converge at the centroid (center) of triangle",
        "Distance to center decreases over time",
      ],
      hint: "Symmetry forces them to converge",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 17,
      question: "You have 12 balls, one is different weight (unknown if heavier or lighter). Find it in 3 weighings.",
      answer: "Weigh 4 vs 4. If equal, different ball is in remaining 4, weigh 1 vs 1. If unequal, different ball is in heavier/lighter group of 4, weigh 2 vs 2 from that group, then 1 vs 1.",
      explanation: [
        "Weighing 1: 4 vs 4",
        "If equal: different in remaining 4, weigh 1 vs 1",
        "If unequal: different in heavier/lighter group",
        "Weighing 2: From suspect group, weigh 2 vs 2",
        "Weighing 3: Identify the different ball and if heavier/lighter",
      ],
      hint: "Divide into groups and use information from each weighing",
      difficulty: "hard",
      targetTime: 120,
    },
    {
      id: 18,
      question: "A lily pad doubles daily and fills a pond in 48 days. When is the pond 1/4 full?",
      answer: "Day 46 (If doubles daily, on day 47 it's 1/2 full, on day 46 it's 1/4 full)",
      explanation: [
        "Day 48: 100% full",
        "Day 47: 50% full (half)",
        "Day 46: 25% full (quarter)",
        "Since it doubles each day, go back 2 days from full",
      ],
      hint: "Work backwards: if it doubles daily, half full the day before",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 19,
      question: "How many trailing zeros in 100! (100 factorial)?",
      answer: "24 (Count factors of 10 = factors of 2×5. More 2s than 5s, so count 5s: floor(100/5) + floor(100/25) = 20 + 4 = 24)",
      explanation: [
        "Trailing zeros come from factors of 10 = 2×5",
        "Count factors of 5 (fewer than 2s)",
        "floor(100/5) = 20, floor(100/25) = 4, floor(100/125) = 0",
        "Total 5s: 20 + 4 = 24",
      ],
      hint: "Count factors of 5 (10 = 2×5, and there are more 2s)",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 20,
      question: "You're 1/4 mile from your car. It starts raining. Should you run or walk to minimize getting wet?",
      answer: "Run (You get wet from rain falling on you while moving. Running reduces time exposed, so less total rain hits you. The rain falling on the ground doesn't matter - only what hits you while moving.)",
      explanation: [
        "Rain falling on you while moving: rate × time",
        "Running reduces time, so less rain hits you",
        "Rain already on ground doesn't matter (you'd step in it either way)",
        "Run to minimize exposure time",
      ],
      hint: "Minimize time exposed to falling rain",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 21,
      question: "A bat and ball cost $1.10. The bat costs $1 more than the ball. How much is the ball?",
      answer: "$0.05 (Let ball = x, bat = x + 1. So x + (x+1) = 1.10, 2x + 1 = 1.10, 2x = 0.10, x = 0.05)",
      explanation: [
        "Let ball = x, bat = x + 1",
        "x + (x + 1) = 1.10",
        "2x + 1 = 1.10",
        "2x = 0.10, so x = 0.05",
        "Ball = $0.05, Bat = $1.05",
      ],
      hint: "Set up equation: ball + (ball + 1) = 1.10",
      difficulty: "easy",
      targetTime: 30,
    },
    {
      id: 22,
      question: "You have a cube. How many different ways can you paint each face one of 6 colors (rotations are same)?",
      answer: "30 ways (Using Burnside's lemma or direct counting: (6^6 + 6×6 + 3×6^4 + 6×6^3 + 8×6^2) / 24 ≈ 30, accounting for 24 rotational symmetries)",
      explanation: [
        "Total colorings: 6^6 = 46,656",
        "Account for 24 rotational symmetries of cube",
        "Use Burnside's lemma to count distinct colorings",
        "Result: approximately 30 distinct colorings",
      ],
      hint: "Use Burnside's lemma to account for rotational symmetries",
      difficulty: "hard",
      targetTime: 120,
    },
    {
      id: 23,
      question: "Four people cross a bridge at night: they take 1, 2, 5, 10 minutes. Only 2 at a time, must share 1 flashlight. Minimum time?",
      answer: "17 minutes (1 and 2 cross (2 min), 1 returns (1 min), 5 and 10 cross (10 min), 2 returns (2 min), 1 and 2 cross (2 min). Total: 2+1+10+2+2 = 17)",
      explanation: [
        "Strategy: Send fastest pair first, then fastest returns",
        "1 and 2 cross: 2 min",
        "1 returns: 1 min",
        "5 and 10 cross: 10 min",
        "2 returns: 2 min",
        "1 and 2 cross: 2 min",
        "Total: 17 minutes",
      ],
      hint: "Minimize time by having fastest people do the returning",
      difficulty: "hard",
      targetTime: 120,
    },
    {
      id: 24,
      question: "A circular track, two runners start at the same point, run in opposite directions. They meet after 10 minutes. If they run in the same direction, faster catches up in 60 minutes. What's the ratio of their speeds?",
      answer: "7:5 (Let speeds be v₁ and v₂, v₁ > v₂. Opposite: (v₁+v₂)×10 = circumference. Same: (v₁-v₂)×60 = circumference. So (v₁+v₂)×10 = (v₁-v₂)×60, solving: v₁/v₂ = 7/5)",
      explanation: [
        "Opposite: (v₁ + v₂) × 10 = C",
        "Same: (v₁ - v₂) × 60 = C",
        "(v₁ + v₂) × 10 = (v₁ - v₂) × 60",
        "v₁ + v₂ = 6(v₁ - v₂) = 6v₁ - 6v₂",
        "7v₂ = 5v₁, so v₁/v₂ = 7/5",
      ],
      hint: "Set up equations for circumference in both cases",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 25,
      question: "You draw 2 cards from a deck. If both are red, you win $100. If both black, you lose $100. If mixed, nothing. What's the expected value?",
      answer: "$0 (P(both red) = (26/52)×(25/51) = 25/102, P(both black) = 25/102, P(mixed) = 52/102. EV = (25/102)×100 + (25/102)×(-100) + (52/102)×0 = 0)",
      explanation: [
        "P(both red) = (26/52) × (25/51) = 25/102",
        "P(both black) = 25/102",
        "P(mixed) = 1 - 50/102 = 52/102",
        "EV = (25/102)×100 + (25/102)×(-100) + 0 = 0",
      ],
      hint: "Calculate probabilities and expected value",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 26,
      question: "A stick is broken at 2 random points. What's the probability the 3 pieces form a triangle?",
      answer: "1/4 (For triangle inequality, all pieces must be < 1/2. Probability = 1/4)",
      explanation: [
        "Triangle inequality: each piece < sum of other two",
        "For unit stick: each piece < 1/2",
        "Probability all three < 1/2: 1/4",
        "Geometric probability problem",
      ],
      hint: "Triangle inequality requires all sides < 1/2 of perimeter",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 27,
      question: "You have a string of 0s and 1s. Flip bits one at a time to maximize expected money: get $1 per 1, lose $1 per 0. Current string: 01001. Strategy?",
      answer: "Flip all bits to 11110 (or keep as is if expected value is already positive). Calculate expected value: 2×$1 - 3×$1 = -$1. Flipping all: 3×$1 - 2×$1 = +$1. So flip all.",
      explanation: [
        "Current: 01001 → 2 ones, 3 zeros → EV = 2 - 3 = -$1",
        "Flipped: 10110 → 3 ones, 2 zeros → EV = 3 - 2 = +$1",
        "Optimal: flip all bits to maximize expected value",
      ],
      hint: "Calculate expected value for current and flipped string",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 28,
      question: "Two trains approach each other at 60 mph each, 120 miles apart. A fly flies at 80 mph between them. How far does the fly travel before trains meet?",
      answer: "40 miles (Trains meet in 1 hour (120 miles / 120 mph relative speed). Fly travels 80 mph × 1 hour = 80 miles. Wait, recalc: relative speed = 60 + 60 = 120 mph, time to meet = 120/120 = 1 hour, fly distance = 80 × 1 = 80 miles)",
      explanation: [
        "Relative speed of trains: 60 + 60 = 120 mph",
        "Time until collision: 120 miles / 120 mph = 1 hour",
        "Fly speed: 80 mph",
        "Distance fly travels: 80 mph × 1 hour = 80 miles",
      ],
      hint: "Calculate time until trains meet, then fly distance",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 29,
      question: "You have an equilateral triangle of side length 1. What's the expected distance between two random points inside it?",
      answer: "Approximately 0.365 (Complex calculation involving integration over triangle area. Result depends on distribution assumption.)",
      explanation: [
        "Requires double integration over triangle area",
        "Calculate E[|P₁ - P₂|] for uniform random points",
        "Result: approximately 0.365 (exact value involves complex integrals)",
        "More complex than circle or square case",
      ],
      hint: "Requires integration over triangle area",
      difficulty: "hard",
      targetTime: 120,
    },
    {
      id: 30,
      question: "A perfectly rational king will divide gold among 5 pirates by seniority. Each votes on the proposal; if ≥50% agree, it's executed, else proposer dies and next tries. How does the senior pirate maximize his gold?",
      answer: "Senior (P5) proposes: P5 gets 98, P3 gets 1, P1 gets 1, P2 and P4 get 0. P3 and P1 vote yes (better than nothing if P5 dies). P5 needs 2 votes besides himself, gives minimum to P3 and P1.",
      explanation: [
        "Work backwards from 2 pirates: P2 gives P1 nothing, keeps all",
        "3 pirates: P3 gives P1 1, keeps 99 (P1 votes yes to avoid 0)",
        "4 pirates: P4 gives P2 1, keeps 99 (P2 votes yes)",
        "5 pirates: P5 gives P1 and P3 each 1, keeps 98 (needs 2 votes)",
      ],
      hint: "Work backwards from smaller number of pirates",
      difficulty: "hard",
      targetTime: 120,
    },
  ] as ProbaQuestion[],
  'coding-project': [
    {
      id: 1,
      prompt: "Moving Average Crossover: Implement a function that takes price data and returns buy/sell signals when a short MA crosses a long MA.",
      tags: ["Coding", "Technical Analysis", "Python"],
      starChecks: [
        "Function signature and input validation",
        "Correct calculation of moving averages",
        "Proper detection of crossover points",
        "Clear return format for signals",
      ],
    },
    {
      id: 2,
      prompt: "Bollinger Bands: Write a function to calculate Bollinger Bands (mean ± 2 std dev) for a given window size.",
      tags: ["Coding", "Technical Analysis", "Statistics"],
      starChecks: [
        "Correct rolling mean calculation",
        "Correct rolling standard deviation",
        "Proper band calculation (mean ± 2σ)",
        "Handles edge cases (window size, data length)",
      ],
    },
    {
      id: 3,
      prompt: "Maximum Drawdown: Given an array of portfolio values, calculate the maximum drawdown.",
      tags: ["Coding", "Risk Metrics", "Algorithm"],
      starChecks: [
        "Correct drawdown calculation (peak to trough)",
        "Efficient algorithm (O(n) time complexity)",
        "Handles edge cases (empty array, single value)",
        "Returns both max drawdown value and period",
      ],
    },
    {
      id: 4,
      prompt: "Sharpe Ratio Calculator: Implement a function to calculate annualized Sharpe ratio from daily returns.",
      tags: ["Coding", "Risk Metrics", "Statistics"],
      starChecks: [
        "Correct calculation: (mean return - risk-free) / (std dev × √252)",
        "Proper annualization (252 trading days)",
        "Handles risk-free rate parameter",
        "Edge case handling (zero variance, negative returns)",
      ],
    },
    {
      id: 5,
      prompt: "Pairs Trading Signal: Given two correlated stocks' prices, detect when the spread deviates >2 std devs.",
      tags: ["Coding", "Pairs Trading", "Statistics"],
      starChecks: [
        "Calculate spread (price1 - price2 or ratio)",
        "Calculate rolling mean and std dev of spread",
        "Detect when |spread - mean| > 2σ",
        "Return clear signals (buy/sell spread)",
      ],
    },
    {
      id: 6,
      prompt: "Order Book Imbalance: Given bid/ask arrays with prices and quantities, calculate the order book imbalance.",
      tags: ["Coding", "Market Microstructure", "Order Book"],
      starChecks: [
        "Calculate bid/ask volumes correctly",
        "Imbalance formula: (bid_volume - ask_volume) / (bid_volume + ask_volume)",
        "Handle edge cases (zero volume, empty book)",
        "Return normalized imbalance value",
      ],
    },
    {
      id: 7,
      prompt: "VWAP Calculator: Implement Volume-Weighted Average Price for a series of trades.",
      tags: ["Coding", "Execution", "VWAP"],
      starChecks: [
        "Correct VWAP formula: Σ(price × volume) / Σ(volume)",
        "Handle cumulative calculation efficiently",
        "Return VWAP for each point in time",
        "Edge case handling (zero volume)",
      ],
    },
    {
      id: 8,
      prompt: "Options Pricer: Implement Black-Scholes formula for European call/put options.",
      tags: ["Coding", "Options", "Black-Scholes"],
      starChecks: [
        "Correct Black-Scholes formula implementation",
        "Calculate d1 and d2 correctly",
        "Use cumulative normal distribution (approximation)",
        "Handle both call and put options",
      ],
    },
    {
      id: 9,
      prompt: "Greeks Calculator: Calculate Delta, Gamma, Vega for an option position.",
      tags: ["Coding", "Options", "Greeks"],
      starChecks: [
        "Delta: ∂Option/∂Stock (numerical or analytical)",
        "Gamma: ∂Delta/∂Stock",
        "Vega: ∂Option/∂Volatility",
        "Handle multiple positions correctly",
      ],
    },
    {
      id: 10,
      prompt: "Candlestick Pattern Detector: Detect specific patterns (e.g., hammer, doji) in OHLC data.",
      tags: ["Coding", "Technical Analysis", "Pattern Recognition"],
      starChecks: [
        "Correct OHLC data parsing",
        "Pattern detection logic (body, wick ratios)",
        "Handle multiple patterns",
        "Return pattern type and confidence",
      ],
    },
    {
      id: 11,
      prompt: "Monte Carlo Simulation: Simulate 10,000 paths of a stock following geometric Brownian motion.",
      tags: ["Coding", "Simulation", "Stochastic Processes"],
      starChecks: [
        "Correct GBM formula: S_t = S_0 × e^((μ-σ²/2)t + σW_t)",
        "Generate random normal increments",
        "Efficient vectorized implementation",
        "Return distribution of final prices",
      ],
    },
    {
      id: 12,
      prompt: "Correlation Matrix: Calculate rolling correlation matrix for multiple assets.",
      tags: ["Coding", "Statistics", "Correlation"],
      starChecks: [
        "Correct correlation calculation: Cov(X,Y) / (σₓ × σᵧ)",
        "Rolling window implementation",
        "Handle missing data",
        "Return symmetric correlation matrix",
      ],
    },
    {
      id: 13,
      prompt: "Mean Reversion Strategy: Implement a mean reversion strategy with entry/exit logic based on z-score.",
      tags: ["Coding", "Strategy", "Mean Reversion"],
      starChecks: [
        "Calculate z-score: (price - mean) / std",
        "Entry: z-score > threshold (e.g., 2)",
        "Exit: z-score returns to mean",
        "Position sizing and risk management",
      ],
    },
    {
      id: 14,
      prompt: "Kelly Criterion: Calculate optimal position size given win rate and payoff ratio.",
      tags: ["Coding", "Position Sizing", "Kelly"],
      starChecks: [
        "Kelly formula: f = (p×b - q) / b where p=win rate, b=payoff ratio, q=1-p",
        "Handle edge cases (f < 0, f > 1)",
        "Fractional Kelly implementation",
        "Return optimal position size",
      ],
    },
    {
      id: 15,
      prompt: "Portfolio Optimization: Implement Markowitz mean-variance optimization (simplified version).",
      tags: ["Coding", "Portfolio", "Optimization"],
      starChecks: [
        "Calculate expected returns and covariance matrix",
        "Objective function: maximize Sharpe or minimize variance",
        "Constraint handling (weights sum to 1, long-only)",
        "Return optimal weights",
      ],
    },
    {
      id: 16,
      prompt: "Time Series Forecasting: Implement simple ARIMA or moving average forecast.",
      tags: ["Coding", "Forecasting", "Time Series"],
      starChecks: [
        "ARIMA model fitting (or simple MA)",
        "Parameter estimation",
        "Forecast generation",
        "Error metrics calculation",
      ],
    },
    {
      id: 17,
      prompt: "Stop Loss Implementation: Given trades and prices, implement trailing stop loss logic.",
      tags: ["Coding", "Risk Management", "Stop Loss"],
      starChecks: [
        "Track highest price since entry",
        "Update stop loss: highest_price - trailing_distance",
        "Exit when price hits stop loss",
        "Handle multiple positions",
      ],
    },
    {
      id: 18,
      prompt: "Market Impact Model: Estimate market impact cost given order size and market liquidity parameters.",
      tags: ["Coding", "Execution", "Market Impact"],
      starChecks: [
        "Market impact formula (e.g., square root model)",
        "Input: order size, average daily volume, volatility",
        "Calculate expected impact cost",
        "Return cost estimate",
      ],
    },
    {
      id: 19,
      prompt: "Cointegration Test: Implement basic cointegration test for pairs trading.",
      tags: ["Coding", "Pairs Trading", "Cointegration"],
      starChecks: [
        "Calculate spread: price1 - β×price2",
        "Test for stationarity (ADF test or simple variance check)",
        "Estimate cointegration coefficient β",
        "Return test statistic and p-value",
      ],
    },
    {
      id: 20,
      prompt: "Risk Parity: Calculate risk parity weights for a portfolio of assets.",
      tags: ["Coding", "Portfolio", "Risk Parity"],
      starChecks: [
        "Calculate inverse volatility weights",
        "Normalize weights to sum to 1",
        "Handle correlation (full risk parity)",
        "Return risk parity weights",
      ],
    },
    {
      id: 21,
      prompt: "High-Frequency Data Aggregation: Aggregate tick data into 1-minute bars (OHLCV).",
      tags: ["Coding", "Data Processing", "Aggregation"],
      starChecks: [
        "Group ticks by time intervals",
        "Calculate OHLC (open, high, low, close)",
        "Sum volumes (V)",
        "Efficient time-based grouping",
      ],
    },
    {
      id: 22,
      prompt: "Slippage Calculator: Calculate expected slippage given order size and average daily volume.",
      tags: ["Coding", "Execution", "Slippage"],
      starChecks: [
        "Slippage model (e.g., proportional to participation rate)",
        "Input: order size, ADV, volatility",
        "Calculate expected slippage",
        "Return slippage estimate in basis points",
      ],
    },
    {
      id: 23,
      prompt: "Factor Exposure: Calculate portfolio exposures to common factors (momentum, value, etc.).",
      tags: ["Coding", "Factor Models", "Exposure"],
      starChecks: [
        "Factor loading calculation for each asset",
        "Portfolio exposure = Σ(weight × factor_loading)",
        "Handle multiple factors",
        "Return factor exposure vector",
      ],
    },
    {
      id: 24,
      prompt: "Regime Detection: Implement simple regime detection (high/low volatility) using HMM or threshold.",
      tags: ["Coding", "Regime Detection", "HMM"],
      starChecks: [
        "Calculate rolling volatility",
        "Threshold-based or HMM-based detection",
        "Identify regime switches",
        "Return regime labels",
      ],
    },
    {
      id: 25,
      prompt: "Backtesting Engine: Build a simple backtesting framework with entry/exit rules.",
      tags: ["Coding", "Backtesting", "Framework"],
      starChecks: [
        "Signal generation from data",
        "Entry/exit rule implementation",
        "Position tracking and P&L calculation",
        "Return performance metrics",
      ],
    },
    {
      id: 26,
      prompt: "Performance Attribution: Break down portfolio returns into asset allocation and selection effects.",
      tags: ["Coding", "Performance", "Attribution"],
      starChecks: [
        "Calculate allocation effect",
        "Calculate selection effect",
        "Interaction effect",
        "Return attribution breakdown",
      ],
    },
    {
      id: 27,
      prompt: "Liquidity Score: Calculate a liquidity score for stocks based on volume and spread.",
      tags: ["Coding", "Liquidity", "Scoring"],
      starChecks: [
        "Combine volume and spread metrics",
        "Normalize to 0-1 scale",
        "Higher volume, lower spread = higher score",
        "Return liquidity score",
      ],
    },
    {
      id: 28,
      prompt: "Signal Aggregation: Combine multiple trading signals with weighted voting.",
      tags: ["Coding", "Signal Processing", "Aggregation"],
      starChecks: [
        "Weighted average of signals",
        "Handle signal normalization",
        "Threshold for final signal",
        "Return aggregated signal",
      ],
    },
    {
      id: 29,
      prompt: "Transaction Cost Analysis: Calculate total trading costs including spread, commissions, and market impact.",
      tags: ["Coding", "Costs", "Analysis"],
      starChecks: [
        "Spread cost calculation",
        "Commission calculation",
        "Market impact estimation",
        "Return total cost breakdown",
      ],
    },
    {
      id: 30,
      prompt: "Real-time P&L Calculator: Track real-time P&L for multiple positions with live price updates.",
      tags: ["Coding", "P&L", "Real-time"],
      starChecks: [
        "Position tracking (quantity, entry price)",
        "Unrealized P&L: (current_price - entry_price) × quantity",
        "Realized P&L from closed positions",
        "Handle multiple positions efficiently",
      ],
    },
  ] as BehavioralQuestion[],
  'statistics-ml': [
    {
      id: 1,
      question: "Explain the Central Limit Theorem and its relevance to trading.",
      answer: "CLT states that sample means of independent observations converge to normal distribution. In trading: portfolio returns, strategy performance metrics, and risk estimates can be approximated as normal, enabling statistical inference and risk management.",
      explanation: [
        "CLT: Sum/average of i.i.d. random variables → normal distribution as n → ∞",
        "Trading relevance: Portfolio returns (sum of asset returns) approximate normal",
        "Enables: confidence intervals, hypothesis testing, VaR calculations",
        "Limitations: Assumes independence, may not hold for fat-tailed distributions",
      ],
      hint: "Think about how portfolio returns are sums of individual returns",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 2,
      question: "What's the difference between Type I and Type II errors in the context of a trading signal?",
      answer: "Type I (false positive): Signal says trade but shouldn't trade (lose money). Type II (false negative): Signal says don't trade but should trade (miss opportunity). In trading, Type I is often costlier.",
      explanation: [
        "Type I error (α): Reject null when true - false positive signal",
        "Type II error (β): Accept null when false - false negative (miss trade)",
        "Trading context: Type I = bad trades, Type II = missed good trades",
        "Power = 1 - β: probability of detecting true signal",
      ],
      hint: "Type I = false alarm, Type II = missed detection",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 3,
      question: "How do you test if two trading strategies have significantly different Sharpe ratios?",
      answer: "Use a statistical test like the Jobson-Korkie test or bootstrap method. Compare Sharpe ratios accounting for correlation between strategies. Null hypothesis: Sharpe ratios are equal.",
      explanation: [
        "Jobson-Korkie test: Tests equality of Sharpe ratios",
        "Accounts for correlation between strategy returns",
        "Bootstrap: Resample returns, calculate Sharpe distribution",
        "Alternative: Compare Sharpe ratios with confidence intervals",
      ],
      hint: "Need to account for correlation and distribution of Sharpe ratio",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 4,
      question: "Explain p-hacking and how it affects quantitative strategy development.",
      answer: "P-hacking is repeatedly testing hypotheses until finding significant results by chance. In quant: testing many factors/parameters until one shows significance inflates false discovery rate. Solutions: multiple testing correction, out-of-sample testing, hold-out data.",
      explanation: [
        "P-hacking: Multiple hypothesis testing without correction",
        "Problem: 5% significance level means 1 in 20 tests significant by chance",
        "In quant: Testing 100 factors → expect 5 significant by chance",
        "Solutions: Bonferroni correction, FDR control, out-of-sample validation",
      ],
      hint: "Multiple testing without correction inflates false positives",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 5,
      question: "What's heteroskedasticity and why does it matter in financial time series?",
      answer: "Heteroskedasticity is non-constant variance over time. In finance: volatility clustering (high vol follows high vol). Matters because: violates OLS assumptions, affects confidence intervals, requires GARCH/volatility models.",
      explanation: [
        "Heteroskedasticity: Variance changes over time",
        "Financial markets: Volatility clustering (ARCH/GARCH effects)",
        "Problems: Standard errors biased, inefficient estimates",
        "Solutions: GARCH models, robust standard errors, volatility weighting",
      ],
      hint: "Think about volatility clustering in markets",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 6,
      question: "Describe the difference between in-sample and out-of-sample testing.",
      answer: "In-sample: testing on data used to build model (optimistic, overfitting risk). Out-of-sample: testing on unseen data (realistic performance). Out-of-sample is the true test of generalization.",
      explanation: [
        "In-sample: same data used for training and testing",
        "Problem: overfitting, optimistic performance",
        "Out-of-sample: separate hold-out data",
        "Out-of-sample performance is what matters for live trading",
      ],
      hint: "In-sample = same data, out-of-sample = new data",
      difficulty: "easy",
      targetTime: 45,
    },
    {
      id: 7,
      question: "What's multiple testing correction and when should you use it?",
      answer: "Adjusts significance levels when testing multiple hypotheses. Methods: Bonferroni (conservative), FDR (less conservative). Use when: testing many factors, parameters, or strategies to control false discovery rate.",
      explanation: [
        "Problem: Testing 100 factors at 5% level → expect 5 significant by chance",
        "Bonferroni: divide α by number of tests",
        "FDR (False Discovery Rate): less conservative alternative",
        "Essential in quant research to avoid false discoveries",
      ],
      hint: "Controls false positives when testing many hypotheses",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 8,
      question: "Explain the difference between correlation and causation with a trading example.",
      answer: "Correlation: two variables move together. Causation: one variable causes the other. Example: High VIX correlates with market drops, but doesn't cause them - both caused by fear/uncertainty. Need controlled experiments or natural experiments to establish causation.",
      explanation: [
        "Correlation: statistical relationship, no direction",
        "Causation: one variable directly causes another",
        "Trading: Many correlations are spurious or reverse causality",
        "Establishing causation requires: controlled experiments, natural experiments, or strong theoretical framework",
      ],
      hint: "Correlation ≠ causation - need evidence of mechanism",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 9,
      question: "What's autocorrelation in time series and how do you detect it?",
      answer: "Autocorrelation: correlation of series with its lagged values. Detect using: ACF plot, Ljung-Box test, or Durbin-Watson test. In finance: indicates predictability, violates independence assumption.",
      explanation: [
        "Autocorrelation: Corr(X_t, X_{t-k}) for lag k",
        "Detection: ACF plot shows correlation at different lags",
        "Tests: Ljung-Box, Durbin-Watson",
        "Trading: Autocorrelation suggests predictability or market inefficiency",
      ],
      hint: "Measure correlation with past values",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 10,
      question: "Describe the bootstrapping method and its use in strategy validation.",
      answer: "Bootstrap: resample data with replacement to estimate distribution of statistics. Use: estimate confidence intervals for Sharpe ratio, test statistics, or strategy returns without assuming distribution. Accounts for finite sample uncertainty.",
      explanation: [
        "Bootstrap: resample original data with replacement",
        "Calculate statistic on each resample",
        "Distribution of statistics approximates true distribution",
        "Useful for: confidence intervals, hypothesis testing without distributional assumptions",
      ],
      hint: "Resample with replacement to estimate distributions",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 11,
      question: "What's the difference between parametric and non-parametric tests?",
      answer: "Parametric: assumes distribution (e.g., normal). Non-parametric: no distribution assumption. Examples: t-test (parametric) vs Mann-Whitney (non-parametric). Non-parametric more robust but less powerful.",
      explanation: [
        "Parametric: assumes data follows specific distribution",
        "Non-parametric: no distributional assumptions",
        "Trade-off: parametric more powerful if assumptions hold, non-parametric more robust",
        "In finance: often use non-parametric due to fat tails",
      ],
      hint: "Parametric assumes distribution, non-parametric doesn't",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 12,
      question: "Explain cross-validation for time series data. Why can't you use standard k-fold CV?",
      answer: "Standard k-fold CV violates temporal order (future data leaks into training). Use: walk-forward validation (train on past, test on future), or purged CV (remove overlapping periods). Preserves temporal structure.",
      explanation: [
        "Standard k-fold: randomly splits data, violates time order",
        "Time series: must respect temporal order",
        "Walk-forward: train on [0:t], test on [t+1:T]",
        "Purged CV: removes overlapping periods between train/test",
      ],
      hint: "Time series requires temporal ordering - use walk-forward",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 13,
      question: "What's stationarity and why is it important for time series modeling?",
      answer: "Stationarity: statistical properties (mean, variance, autocorrelation) constant over time. Important because: most time series models assume stationarity, enables forecasting, and makes statistical inference valid.",
      explanation: [
        "Stationary: mean, variance, autocorrelation don't change over time",
        "Most models (ARIMA, etc.) assume stationarity",
        "Non-stationary: trends, changing volatility",
        "Solution: differencing, detrending, or use models that handle non-stationarity",
      ],
      hint: "Stationary = constant statistical properties over time",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 14,
      question: "Describe the Augmented Dickey-Fuller test and what it tells you.",
      answer: "ADF test: tests null hypothesis that time series has unit root (non-stationary). If reject null (p < 0.05), series is stationary. Used to check if differencing needed before modeling.",
      explanation: [
        "ADF: tests H₀: series has unit root (non-stationary)",
        "If p < 0.05: reject null, series is stationary",
        "If p > 0.05: fail to reject, series is non-stationary (need differencing)",
        "Critical for time series modeling",
      ],
      hint: "Tests for unit root (non-stationarity)",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 15,
      question: "What's the difference between GARCH and simple rolling volatility?",
      answer: "Rolling volatility: equal weights to all observations in window. GARCH: weights recent observations more, models volatility clustering, predicts future volatility. GARCH adapts faster to regime changes.",
      explanation: [
        "Rolling: equal weights, simple average of squared returns",
        "GARCH: exponential weighting, recent data more important",
        "GARCH: models volatility clustering (ARCH effects)",
        "GARCH: can forecast future volatility",
      ],
      hint: "GARCH uses weighted average and models clustering",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 16,
      question: "Explain Maximum Likelihood Estimation in the context of fitting distributions to returns.",
      answer: "MLE: finds parameters that maximize probability of observing the data. For returns: assume distribution (e.g., normal), write likelihood function, maximize log-likelihood. Gives parameter estimates (mean, variance) that best fit observed returns.",
      explanation: [
        "MLE: maximize P(data | parameters)",
        "For returns: assume distribution, write likelihood",
        "Maximize log-likelihood (easier than likelihood)",
        "Gives best-fit parameters for assumed distribution",
      ],
      hint: "Find parameters that maximize probability of data",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 17,
      question: "What's the difference between L1 and L2 regularization? When would you use each?",
      answer: "L1 (Lasso): |w| penalty, drives weights to zero (sparsity). L2 (Ridge): w² penalty, shrinks weights but keeps them. Use L1 for feature selection, L2 when all features might matter. Can combine (Elastic Net).",
      explanation: [
        "L1: |w| penalty → sparsity (feature selection)",
        "L2: w² penalty → shrinkage (all features kept)",
        "L1: when many irrelevant features",
        "L2: when all features potentially relevant",
      ],
      hint: "L1 = sparsity, L2 = shrinkage",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 18,
      question: "Describe how Principal Component Analysis could be used for portfolio construction.",
      answer: "PCA finds principal components (linear combinations) that explain most variance. Use: reduce dimensionality, identify risk factors, construct factor-mimicking portfolios, or reduce noise in covariance matrix estimation.",
      explanation: [
        "PCA: finds directions of maximum variance",
        "First PC often represents 'market factor'",
        "Use PCs as risk factors for portfolio construction",
        "Reduces dimensionality, improves covariance estimation",
      ],
      hint: "PCA finds risk factors from return data",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 19,
      question: "What's the curse of dimensionality and how does it affect ML models in trading?",
      answer: "Curse: as dimensions increase, data becomes sparse, distances become similar, models overfit. In trading: many features (100s), limited data (years), leads to overfitting. Solutions: feature selection, regularization, dimensionality reduction.",
      explanation: [
        "Curse: high dimensions → sparse data, all points equidistant",
        "Trading: many features, limited historical data",
        "Problem: overfitting, poor generalization",
        "Solutions: PCA, feature selection, regularization",
      ],
      hint: "High dimensions + limited data = overfitting",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 20,
      question: "Explain ensemble methods (bagging, boosting) and their application to trading.",
      answer: "Bagging: average predictions from models on bootstrapped data (reduces variance). Boosting: sequentially fit models to correct previous errors (reduces bias). In trading: Random Forest (bagging), XGBoost (boosting) for signal generation.",
      explanation: [
        "Bagging: parallel models, average predictions (variance reduction)",
        "Boosting: sequential models, correct errors (bias reduction)",
        "Trading: Random Forest, XGBoost for alpha signals",
        "Ensembles: more robust, better generalization",
      ],
      hint: "Bagging = parallel, Boosting = sequential",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 21,
      question: "What's the difference between Random Forest and Gradient Boosting?",
      answer: "Random Forest: bagging of decision trees, parallel training, reduces variance. Gradient Boosting: sequential trees correcting errors, reduces bias. RF: faster, less overfitting. GB: often more accurate but slower, more prone to overfitting.",
      explanation: [
        "Random Forest: bagging, parallel, variance reduction",
        "Gradient Boosting: sequential, bias reduction",
        "RF: faster, more robust",
        "GB: often more accurate, but slower and can overfit",
      ],
      hint: "RF = parallel bagging, GB = sequential boosting",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 22,
      question: "Describe how you'd use cross-entropy loss vs MSE for a trading classifier.",
      answer: "Cross-entropy: for classification (predict up/down), penalizes wrong class predictions. MSE: for regression (predict return magnitude). Cross-entropy better for binary classification, MSE for continuous targets.",
      explanation: [
        "Cross-entropy: for classification (binary or multi-class)",
        "MSE: for regression (continuous targets)",
        "Trading classifier (up/down): use cross-entropy",
        "Trading regressor (return size): use MSE",
      ],
      hint: "Cross-entropy for classification, MSE for regression",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 23,
      question: "What's a confusion matrix and how do you interpret it for trading signals?",
      answer: "Confusion matrix: table of predicted vs actual. For trading: rows = predicted (buy/sell), columns = actual (up/down). Metrics: precision (of buys, how many correct), recall (of actual ups, how many caught), F1 score.",
      explanation: [
        "Confusion matrix: predicted vs actual classification",
        "Trading: buy/sell predictions vs actual up/down",
        "Metrics: precision, recall, F1, accuracy",
        "Helps understand type of errors (false positives vs false negatives)",
      ],
      hint: "Table showing predicted vs actual classifications",
      difficulty: "easy",
      targetTime: 45,
    },
    {
      id: 24,
      question: "Explain the ROC curve and AUC in the context of binary trading signals.",
      answer: "ROC: plots True Positive Rate vs False Positive Rate at different thresholds. AUC: area under curve, measures classifier quality (1.0 = perfect, 0.5 = random). Higher AUC = better signal quality. AUC = 0.7+ is good for trading.",
      explanation: [
        "ROC: TPR (sensitivity) vs FPR (1-specificity)",
        "AUC: area under ROC curve",
        "AUC = 1.0: perfect classifier, 0.5: random",
        "Trading: AUC > 0.6 useful, > 0.7 good",
      ],
      hint: "ROC shows trade-off between true and false positives",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 25,
      question: "What's batch normalization and why might it help in financial neural networks?",
      answer: "Batch norm: normalizes layer inputs to mean 0, variance 1. Helps: faster training, higher learning rates, reduces internal covariate shift. In finance: can help with non-stationary data, though may not always help due to small batch sizes.",
      explanation: [
        "Batch norm: normalize inputs to each layer",
        "Benefits: faster convergence, higher learning rates",
        "Finance: may help with non-stationary data",
        "Limitation: small batch sizes in finance can hurt performance",
      ],
      hint: "Normalizes layer inputs to stabilize training",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 26,
      question: "Describe the vanishing gradient problem and how it affects deep learning for trading.",
      answer: "Vanishing gradient: gradients become very small in deep networks, early layers don't learn. In finance: deep networks may not work well. Solutions: ReLU activation, residual connections, careful initialization, or use shallower networks.",
      explanation: [
        "Problem: gradients shrink exponentially through layers",
        "Early layers get tiny gradients, don't update",
        "Finance: deep networks often don't help",
        "Solutions: ReLU, skip connections, or shallow networks",
      ],
      hint: "Gradients become too small in deep networks",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 27,
      question: "What's the difference between online learning and batch learning for live trading?",
      answer: "Batch: train on all data, then deploy. Online: update model continuously as new data arrives. Online: adapts to regime changes, but can be unstable. Batch: more stable but may become stale. Hybrid: periodic retraining.",
      explanation: [
        "Batch: train once, deploy fixed model",
        "Online: continuously update with new data",
        "Online: adapts to changes, but can be noisy",
        "Trading: often use periodic retraining (semi-online)",
      ],
      hint: "Online = continuous update, Batch = train once",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 28,
      question: "Explain how you'd handle imbalanced classes in trading data (rare events).",
      answer: "Methods: oversample minority class (SMOTE), undersample majority, class weights (penalize misclassifying minority more), different metrics (F1, AUC-ROC instead of accuracy), or cost-sensitive learning.",
      explanation: [
        "Problem: rare events (e.g., crashes) are minority class",
        "Oversampling: duplicate or generate minority samples",
        "Class weights: penalize minority misclassification more",
        "Metrics: use F1, AUC instead of accuracy",
      ],
      hint: "Balance classes or adjust loss function",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 29,
      question: "What's transfer learning and could it be applied to trading?",
      answer: "Transfer learning: use model trained on one task for another. In trading: train on one asset/market, apply to another. Challenges: non-stationarity, different regimes. Possible for: similar assets, different time periods with care.",
      explanation: [
        "Transfer: pre-train on source, fine-tune on target",
        "Trading: train on one market, apply to another",
        "Challenges: regime differences, non-stationarity",
        "May work for: similar assets, related markets",
      ],
      hint: "Use knowledge from one domain in another",
      difficulty: "hard",
      targetTime: 90,
    },
    {
      id: 30,
      question: "Describe A/B testing methodology for comparing two trading strategies.",
      answer: "A/B test: randomly assign trades to strategy A or B, compare performance. Key: random assignment, sufficient sample size, control for market conditions. Metrics: Sharpe ratio, returns, risk-adjusted returns. Statistical test for significance.",
      explanation: [
        "Random assignment: each trade to A or B",
        "Compare: returns, Sharpe, risk metrics",
        "Statistical test: are differences significant?",
        "Challenges: market regime changes, sample size",
      ],
      hint: "Random assignment and statistical comparison",
      difficulty: "medium",
      targetTime: 75,
    },
  ] as MLQuestion[],
  'trading-intuition': [
    {
      id: 1,
      question: "Two highly correlated stocks diverge suddenly. What are potential causes and how would you trade it?",
      answer: "Causes: company-specific news, sector rotation, liquidity events, or correlation breakdown. Trade: pairs trade (long underperformer, short outperformer) expecting reversion, but check if divergence is fundamental vs temporary.",
      explanation: [
        "Potential causes: Fundamental change, temporary dislocation, liquidity",
        "Trading approach: Pairs trade if mean-reverting",
        "Risk: Divergence could be permanent (fundamental change)",
        "Check: News, volume, whether correlation breakdown is structural",
      ],
      hint: "Consider whether divergence is temporary or permanent",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 2,
      question: "Volatility is at historic lows. How should this affect your strategy selection and position sizing?",
      answer: "Low vol suggests: reduce position sizes (vol will normalize), favor mean reversion over momentum, increase hedging, prepare for vol spike. Low vol often precedes high vol periods.",
      explanation: [
        "Low vol environment: Volatility clustering suggests vol will rise",
        "Position sizing: Reduce sizes anticipating vol normalization",
        "Strategy: Mean reversion may work better than momentum",
        "Risk: Vol spikes can cause large losses if over-leveraged",
      ],
      hint: "Volatility tends to cluster and mean-revert",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 3,
      question: "You observe large volume without price movement. What might this indicate?",
      answer: "Possible causes: large block trade at midpoint, market maker inventory management, accumulation/distribution, or information asymmetry. Could signal upcoming move or institutional positioning.",
      explanation: [
        "High volume, low price change: Unusual activity",
        "Possible causes: Block trades, market making, accumulation",
        "Trading implication: May signal upcoming directional move",
        "Investigate: Who is trading, order flow, market microstructure",
      ],
      hint: "Think about what causes volume without price impact",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 4,
      question: "A stock's implied volatility is much higher than realized volatility. What trade does this suggest?",
      answer: "Sell volatility (short options, sell straddles/strangles). IV > RV means options are expensive relative to actual movement. Profit from vol crush if realized vol stays low.",
      explanation: [
        "IV > RV: Options are expensive relative to actual movement",
        "Trade: Sell volatility (short options, sell straddles)",
        "Profit from: Volatility crush, theta decay",
        "Risk: Large move could cause losses",
      ],
      hint: "When IV > RV, options are rich - sell them",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 5,
      question: "You notice your alpha factor worked well for 3 years but stopped working 6 months ago. What do you do?",
      answer: "Investigate: regime change, factor crowding, data issues, or overfitting. Check: out-of-sample performance, factor exposure changes, market regime. Consider: reducing allocation, modifying factor, or killing strategy if fundamental change.",
      explanation: [
        "Possible causes: Regime change, crowding, overfitting, data issues",
        "Investigation: Check regime, factor exposure, correlation breakdown",
        "Action: Reduce allocation, modify factor, or kill strategy",
        "Learning: Factor decay is normal, need continuous research",
      ],
      hint: "Factor decay is common - investigate cause before abandoning",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 6,
      question: "End-of-day vs intraday patterns: which is more likely to persist and why?",
      answer: "End-of-day patterns more likely to persist. Reasons: less noise (aggregated data), institutional flows (end-of-day rebalancing), less competition from HFT. Intraday patterns: more noise, more competition, harder to capture.",
      explanation: [
        "End-of-day: aggregated, less noise",
        "Institutional flows: rebalancing, fund flows",
        "Less HFT competition at end of day",
        "Intraday: more noise, more competition, faster decay",
      ],
      hint: "Consider noise, competition, and institutional behavior",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 7,
      question: "A pairs trade's spread has widened beyond your model's prediction. What factors do you consider before adding to the position?",
      answer: "Check: fundamental news (permanent vs temporary), liquidity (can you exit?), correlation breakdown (structural change?), model validity (is model still correct?), position size (risk limits), and time horizon (mean reversion timeframe).",
      explanation: [
        "Fundamental: is divergence permanent?",
        "Liquidity: can you exit if wrong?",
        "Model: is cointegration still valid?",
        "Risk: position size, drawdown limits",
      ],
      hint: "Assess if divergence is temporary or permanent",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 8,
      question: "Your momentum strategy is losing money in a trending market. What might be wrong?",
      answer: "Possible issues: wrong timeframe (too fast/slow), entry timing (entering too late), position sizing (too small), transaction costs (overtrading), or regime change (momentum not working in this regime). Check: are you actually capturing the trend?",
      explanation: [
        "Timeframe: momentum may work on different horizon",
        "Entry: entering after trend exhausted",
        "Costs: transaction costs eating returns",
        "Regime: momentum may not work in current market",
      ],
      hint: "Check timeframe, entry timing, costs, and regime",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 9,
      question: "How would you trade around a scheduled macro announcement (e.g., Fed decision)?",
      answer: "Options: avoid trading (reduce exposure), trade volatility (long vol before, short after), directional bet (if strong view), or wait for reaction (trade the fade). Risk: high volatility, gap risk, liquidity issues. Often best to reduce exposure.",
      explanation: [
        "Reduce exposure: avoid high volatility periods",
        "Volatility trade: long vol before, short after",
        "Directional: if strong view on outcome",
        "Reaction trade: trade the fade after initial move",
      ],
      hint: "Consider volatility, liquidity, and gap risk",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 10,
      question: "You discover a high Sharpe ratio strategy but maximum position size is limited. How do you think about capacity?",
      answer: "Capacity: maximum AUM before strategy degrades. Factors: market depth, impact costs, competition. If capacity limited: accept it, find similar uncorrelated strategies, or optimize for capacity (lower Sharpe but scalable).",
      explanation: [
        "Capacity: AUM before alpha degrades",
        "Factors: liquidity, market impact, competition",
        "Solutions: diversify to similar strategies",
        "Trade-off: high Sharpe vs high capacity",
      ],
      hint: "Balance Sharpe ratio with scalability",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 11,
      question: "A stock exhibits strong mean reversion on short timescales but momentum on long timescales. How do you reconcile this?",
      answer: "Different timeframes have different dynamics. Short-term: microstructure effects, noise, mean reversion. Long-term: fundamentals, trends, momentum. Use: multi-timeframe approach, or separate strategies for each timeframe.",
      explanation: [
        "Short-term: noise, microstructure, mean reversion",
        "Long-term: fundamentals, trends, momentum",
        "Solution: multi-timeframe models",
        "Or: separate strategies for each horizon",
      ],
      hint: "Different timeframes have different dynamics",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 12,
      question: "Your model says buy but market microstructure indicators suggest selling pressure. Which do you trust?",
      answer: "Microstructure often more reliable for short-term. Check: timeframe (model may be longer-term), recent data (model may use stale data), and combine both (model for direction, microstructure for timing). Often: reduce position or wait.",
      explanation: [
        "Microstructure: real-time, short-term",
        "Model: may be longer-term, use older data",
        "Combine: model for direction, microstructure for timing",
        "When conflict: reduce position or wait",
      ],
      hint: "Microstructure for timing, model for direction",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 13,
      question: "You're seeing high correlation breakdown across assets. What does this suggest about market regime?",
      answer: "Suggests: regime change, stress period, or flight to quality. High correlation breakdown often precedes or accompanies volatility spikes, market stress. Action: reduce risk, increase hedging, or trade the volatility.",
      explanation: [
        "Correlation breakdown: regime change indicator",
        "Often precedes: volatility spikes, stress",
        "May indicate: flight to quality, uncertainty",
        "Action: reduce risk, hedge, or trade volatility",
      ],
      hint: "Correlation breakdown signals regime change",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 14,
      question: "A factor that has been rewarded (e.g., value) underperforms for an extended period. Is it dead or dormant?",
      answer: "Hard to distinguish. Check: fundamental reason (regime change vs temporary), historical precedent (has it recovered before?), and valuation (is it extreme?). Often: reduce allocation but don't eliminate (factors can come back).",
      explanation: [
        "Dead: structural change, won't recover",
        "Dormant: temporary, will recover",
        "Check: history, fundamentals, valuation",
        "Often: reduce but don't eliminate",
      ],
      hint: "Distinguish structural change from temporary underperformance",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 15,
      question: "How would you trade around earnings announcements? Is the risk-reward favorable?",
      answer: "High risk: gap risk, volatility, unpredictable. Strategies: avoid (reduce exposure), trade volatility (long vol before), or trade the reaction (fade initial move). Risk-reward: often unfavorable due to high volatility and unpredictable outcomes.",
      explanation: [
        "High risk: gap risk, high volatility",
        "Strategies: avoid, trade vol, or trade reaction",
        "Risk-reward: often unfavorable",
        "Many quants avoid earnings periods",
      ],
      hint: "High volatility and gap risk make it challenging",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 16,
      question: "Your statistical arbitrage strategy shows decreasing profitability over time. What are potential causes?",
      answer: "Causes: crowding (others copying), regime change (market structure changed), overfitting (never worked out-of-sample), transaction costs (increased), or data issues. Investigate: is it all strategies or just this one?",
      explanation: [
        "Crowding: others discovered same strategy",
        "Regime: market structure changed",
        "Overfitting: strategy never truly worked",
        "Costs: transaction costs increased",
      ],
      hint: "Check crowding, regime, overfitting, and costs",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 17,
      question: "You observe that your strategy's performance is highly skewed (many small wins, few large losses). Is this problematic?",
      answer: "Yes, problematic. Skewed returns: high tail risk, may blow up. Check: risk management (stop losses?), position sizing (too large?), or strategy design (picking up pennies in front of steamroller). Need: better risk controls.",
      explanation: [
        "Skewed: many small wins, few large losses",
        "Problem: tail risk, potential blow-up",
        "Causes: poor risk management, position sizing",
        "Solution: stop losses, position limits, better risk controls",
      ],
      hint: "Skewed returns indicate tail risk",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 18,
      question: "Market liquidity is deteriorating. How does this affect your strategy implementation?",
      answer: "Effects: higher transaction costs, wider spreads, slippage, difficulty exiting. Actions: reduce position sizes, widen stop losses, avoid illiquid names, increase holding periods, or pause strategy until liquidity returns.",
      explanation: [
        "Higher costs: spreads, slippage, impact",
        "Exit risk: difficulty closing positions",
        "Actions: reduce size, widen stops, avoid illiquid",
        "May need to pause strategy",
      ],
      hint: "Deteriorating liquidity increases costs and exit risk",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 19,
      question: "You find a strategy that works only on Mondays. Is this exploitable or data mining?",
      answer: "Likely data mining. Check: out-of-sample performance, theoretical reason (why Mondays?), multiple testing correction (testing many day-of-week effects). If robust: may be calendar effect (e.g., weekend news), but be skeptical.",
      explanation: [
        "Likely: data mining, multiple testing",
        "Check: out-of-sample, theoretical reason",
        "If robust: may be calendar effect",
        "Be very skeptical of day-of-week effects",
      ],
      hint: "Be skeptical - likely data mining unless robust",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 20,
      question: "A new exchange/venue launches. How might this affect your existing strategies?",
      answer: "Effects: fragmentation (liquidity split), new opportunities (arbitrage), or competition (others may exploit faster). Monitor: volume migration, spread changes, latency requirements. May need: new data feeds, faster execution, or strategy adjustments.",
      explanation: [
        "Fragmentation: liquidity split across venues",
        "Opportunities: cross-venue arbitrage",
        "Competition: others may exploit faster",
        "May need: new infrastructure, faster execution",
      ],
      hint: "New venue changes market structure",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 21,
      question: "You're competing with HFT firms. What timeframes and strategies remain viable?",
      answer: "Viable: longer timeframes (minutes to days), fundamental strategies, less liquid markets, or strategies requiring human judgment. Avoid: millisecond strategies, simple arbitrage, or highly liquid markets where HFT dominates.",
      explanation: [
        "HFT dominates: millisecond, simple arbitrage",
        "Viable: longer horizons, fundamental, less liquid",
        "Or: strategies requiring judgment, complex analysis",
        "Focus on areas where speed less important",
      ],
      hint: "Focus on timeframes and strategies where speed less critical",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 22,
      question: "How do corporate actions (splits, dividends) affect backtesting and live trading?",
      answer: "Splits: adjust prices (divide by split ratio). Dividends: adjust for ex-dividend drops. Critical: adjust historical prices, or backtest will be wrong. Live: handle automatically or manually. Often: use adjusted prices from data provider.",
      explanation: [
        "Splits: price adjustment needed",
        "Dividends: ex-dividend price drop",
        "Backtest: must use adjusted prices",
        "Live: handle automatically or manually",
      ],
      hint: "Must adjust prices for corporate actions",
      difficulty: "medium",
      targetTime: 60,
    },
    {
      id: 23,
      question: "Your strategy has negative skew (frequent small gains, rare large losses). How do you manage risk?",
      answer: "Risk management: strict stop losses, position limits, reduce leverage, or hedge tail risk (options). Problem: strategy may be 'picking up pennies in front of steamroller'. Consider: is strategy fundamentally flawed?",
      explanation: [
        "Negative skew: tail risk",
        "Risk controls: stops, limits, hedging",
        "Problem: may indicate flawed strategy",
        "Consider: redesign strategy to reduce tail risk",
      ],
      hint: "Negative skew indicates tail risk - need strict controls",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 24,
      question: "You observe clustering of returns (volatility clustering). How do you incorporate this?",
      answer: "Use: GARCH models (forecast volatility), regime-switching models, or volatility-adjusted position sizing. Volatility clustering: high vol follows high vol. Incorporate: increase position when vol low, decrease when vol high.",
      explanation: [
        "Volatility clustering: high vol follows high vol",
        "Models: GARCH, regime-switching",
        "Application: volatility-adjusted sizing",
        "Size positions inversely to volatility",
      ],
      hint: "Use GARCH or volatility-adjusted sizing",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 25,
      question: "A regulatory change is announced. How do you assess its impact on your strategies?",
      answer: "Assess: read regulation, identify affected strategies, estimate impact (costs, constraints), test scenarios, and plan adjustments. May need: reduce certain strategies, modify execution, or find alternatives. Monitor: implementation timeline.",
      explanation: [
        "Read: understand regulation",
        "Identify: which strategies affected",
        "Estimate: costs, constraints, impact",
        "Plan: adjustments or alternatives",
      ],
      hint: "Systematically assess impact and plan adjustments",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 26,
      question: "You find that your strategy works better during certain market hours. How do you exploit this?",
      answer: "If robust: trade only during those hours, or weight signals more during those hours. But: be very skeptical - likely data mining. Check: out-of-sample, theoretical reason, multiple testing. If truly robust: implement time-based filters.",
      explanation: [
        "If robust: trade only during those hours",
        "Or: weight signals by time",
        "But: be very skeptical of time effects",
        "Check: out-of-sample, multiple testing",
      ],
      hint: "Be skeptical unless very robust",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 27,
      question: "Your quant signal conflicts with fundamental analysis. How do you weigh these inputs?",
      answer: "Consider: timeframe (quant may be short-term, fundamental long-term), confidence in each signal, and combine (weighted average or use one as filter). Often: quant for timing, fundamental for direction, or use both with different weights.",
      explanation: [
        "Timeframe: quant vs fundamental may differ",
        "Confidence: weight by signal strength",
        "Combine: weighted average or filtering",
        "Often: quant for timing, fundamental for direction",
      ],
      hint: "Consider timeframe and confidence in each signal",
      difficulty: "medium",
      targetTime: 90,
    },
    {
      id: 28,
      question: "You notice your strategy's alpha is entirely explained by factor exposures. What does this mean?",
      answer: "Means: strategy has no true alpha, just factor exposure (e.g., market, value, momentum). Implication: can replicate with factor portfolio, lower fees. Action: either accept (factor investing) or find true alpha (idiosyncratic returns).",
      explanation: [
        "No true alpha: returns from factor exposure",
        "Can replicate: with factor portfolio",
        "Implication: lower fees, simpler implementation",
        "Or: find true idiosyncratic alpha",
      ],
      hint: "Factor exposure means no true alpha",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 29,
      question: "Market impact costs are higher than expected. How do you adjust your trading?",
      answer: "Adjust: reduce position sizes, trade slower (TWAP/VWAP), use dark pools, split orders, or avoid illiquid names. May need: revise expected returns, reduce turnover, or focus on more liquid markets.",
      explanation: [
        "Reduce size: smaller positions",
        "Trade slower: TWAP, VWAP",
        "Execution: dark pools, order splitting",
        "Focus: more liquid markets",
      ],
      hint: "Reduce size, trade slower, or use better execution",
      difficulty: "medium",
      targetTime: 75,
    },
    {
      id: 30,
      question: "You observe that retail trader sentiment is a contrarian indicator. How do you systematically exploit this?",
      answer: "Measure: retail flow data, sentiment indices, or social media. Strategy: fade retail (trade opposite). But: be careful - may not always work, need robust signal. Test: out-of-sample, check if relationship persists.",
      explanation: [
        "Measure: retail flow, sentiment data",
        "Strategy: contrarian (fade retail)",
        "Test: out-of-sample validation",
        "Careful: relationship may not persist",
      ],
      hint: "Measure retail sentiment and trade contrarian",
      difficulty: "medium",
      targetTime: 90,
    },
  ] as TradingQuestion[],
  'research-discussion': [
    {
      id: 1,
      prompt: "Walk me through your research process from idea generation to implementation.",
      tags: ["Research Process", "Methodology", "Implementation"],
      starChecks: [
        "Clear stages: idea → hypothesis → backtest → validation → implementation",
        "Specific tools and methods used",
        "How you validate ideas before implementation",
        "Risk management and monitoring process",
      ],
    },
    {
      id: 2,
      prompt: "Describe a research project that failed. What did you learn?",
      tags: ["Learning", "Failure", "Reflection"],
      starChecks: [
        "Specific failed project described",
        "Honest assessment of why it failed",
        "Key lessons learned",
        "How you applied learnings to future projects",
      ],
    },
    {
      id: 3,
      prompt: "How do you generate new trading ideas? What sources do you use?",
      tags: ["Idea Generation", "Research", "Sources"],
      starChecks: [
        "Multiple sources mentioned (papers, data, market observation)",
        "Systematic approach to idea generation",
        "How you prioritize and filter ideas",
        "Examples of successful ideas generated",
      ],
    },
    {
      id: 4,
      prompt: "Explain a recent paper you read that interested you and how it might apply to trading.",
      tags: ["Research", "Academic", "Application"],
      starChecks: [
        "Specific paper and key concepts explained",
        "Clear understanding of the research",
        "How it applies to trading",
        "Potential implementation approach",
      ],
    },
    {
      id: 5,
      prompt: "How do you balance complexity and interpretability in your models?",
      tags: ["Model Design", "Trade-offs", "Interpretability"],
      starChecks: [
        "Understanding of complexity vs interpretability trade-off",
        "Framework for making decisions",
        "Examples of when to use each approach",
        "How you communicate complex models",
      ],
    },
    {
      id: 6,
      prompt: "What's your approach to feature engineering for financial data?",
      tags: ["Feature Engineering", "Data", "Research"],
      starChecks: [
        "Domain knowledge vs data-driven features",
        "Handling non-stationarity and regime changes",
        "Feature selection methods",
        "Examples of successful features",
      ],
    },
    {
      id: 7,
      prompt: "Describe how you'd test if a new factor adds value to existing models.",
      tags: ["Factor Testing", "Validation", "Research"],
      starChecks: [
        "Incremental information content test",
        "Out-of-sample validation",
        "Statistical significance testing",
        "Economic significance assessment",
      ],
    },
    {
      id: 8,
      prompt: "How do you handle the non-stationarity of financial markets in your research?",
      tags: ["Non-Stationarity", "Time Series", "Research"],
      starChecks: [
        "Detecting non-stationarity (ADF test, etc.)",
        "Methods: differencing, detrending, regime models",
        "Walk-forward validation",
        "Adaptive models that handle regime changes",
      ],
    },
    {
      id: 9,
      prompt: "What's your framework for deciding when to kill a strategy?",
      tags: ["Strategy Management", "Decision Making", "Research"],
      starChecks: [
        "Performance metrics and thresholds",
        "Time period for evaluation",
        "Distinguish temporary vs permanent degradation",
        "Process for strategy retirement",
      ],
    },
    {
      id: 10,
      prompt: "How do you think about the decay of trading signals over time?",
      tags: ["Signal Decay", "Factor Lifecycle", "Research"],
      starChecks: [
        "Understanding why signals decay (crowding, regime)",
        "Measuring signal decay",
        "Strategies to extend signal life",
        "When to abandon vs modify signals",
      ],
    },
    {
      id: 11,
      prompt: "Describe your approach to portfolio construction when you have multiple uncorrelated alphas.",
      tags: ["Portfolio Construction", "Alpha Combination", "Research"],
      starChecks: [
        "Risk parity or equal risk contribution",
        "Kelly criterion or optimal sizing",
        "Correlation structure consideration",
        "Diversification benefits",
      ],
    },
    {
      id: 12,
      prompt: "How do you measure the economic significance vs statistical significance of a signal?",
      tags: ["Significance", "Evaluation", "Research"],
      starChecks: [
        "Statistical: p-values, confidence intervals",
        "Economic: Sharpe ratio, returns, capacity",
        "Transaction costs consideration",
        "Balancing both types of significance",
      ],
    },
    {
      id: 13,
      prompt: "What role does domain knowledge vs data-driven discovery play in your research?",
      tags: ["Research Philosophy", "Domain Knowledge", "Data Science"],
      starChecks: [
        "Balance between theory and empirics",
        "When to use each approach",
        "Combining both effectively",
        "Examples of successful hybrid approaches",
      ],
    },
    {
      id: 14,
      prompt: "How do you avoid overfitting when you have limited historical data?",
      tags: ["Overfitting", "Validation", "Research"],
      starChecks: [
        "Cross-validation methods for time series",
        "Regularization techniques",
        "Simple models vs complex",
        "Out-of-sample testing",
      ],
    },
    {
      id: 15,
      prompt: "Describe your process for hyperparameter tuning without data snooping.",
      tags: ["Hyperparameter Tuning", "Validation", "Research"],
      starChecks: [
        "Nested cross-validation",
        "Walk-forward optimization",
        "Separate validation set",
        "Avoiding look-ahead bias",
      ],
    },
    {
      id: 16,
      prompt: "How would you research the effectiveness of alternative data sources?",
      tags: ["Alternative Data", "Research", "Data Sources"],
      starChecks: [
        "Hypothesis formation",
        "Data acquisition and cleaning",
        "Feature extraction methods",
        "Validation and backtesting",
      ],
    },
    {
      id: 17,
      prompt: "What's your approach to combining signals with different forecast horizons?",
      tags: ["Signal Combination", "Multi-Horizon", "Research"],
      starChecks: [
        "Weighting by horizon",
        "Separate models vs combined",
        "Handling different update frequencies",
        "Optimal combination methods",
      ],
    },
    {
      id: 18,
      prompt: "How do you think about the trade-off between turnover and alpha?",
      tags: ["Turnover", "Alpha", "Trade-offs", "Research"],
      starChecks: [
        "Transaction costs vs alpha",
        "Optimal rebalancing frequency",
        "Turnover constraints",
        "Optimizing net returns",
      ],
    },
    {
      id: 19,
      prompt: "Describe how you'd research market microstructure effects on your strategy.",
      tags: ["Market Microstructure", "Research", "Execution"],
      starChecks: [
        "Identifying microstructure effects",
        "Measuring impact (spread, slippage)",
        "Incorporating into strategy",
        "Execution optimization",
      ],
    },
    {
      id: 20,
      prompt: "What's your process for validating that a backtest is realistic?",
      tags: ["Backtesting", "Validation", "Research"],
      starChecks: [
        "Transaction cost assumptions",
        "Slippage and market impact",
        "Survivorship bias checks",
        "Regime coverage",
      ],
    },
    {
      id: 21,
      prompt: "How do you think about strategy capacity in your research?",
      tags: ["Capacity", "Scalability", "Research"],
      starChecks: [
        "Estimating capacity limits",
        "Factors affecting capacity",
        "Optimizing for capacity vs Sharpe",
        "Diversification to increase capacity",
      ],
    },
    {
      id: 22,
      prompt: "Describe how you'd analyze why a strategy stopped working.",
      tags: ["Strategy Analysis", "Debugging", "Research"],
      starChecks: [
        "Performance attribution analysis",
        "Regime change detection",
        "Factor exposure changes",
        "Crowding analysis",
      ],
    },
    {
      id: 23,
      prompt: "What metrics beyond Sharpe ratio do you consider important for strategy evaluation?",
      tags: ["Performance Metrics", "Evaluation", "Research"],
      starChecks: [
        "Sortino, Calmar, Information ratio",
        "Maximum drawdown",
        "Win rate, profit factor",
        "Tail risk metrics",
      ],
    },
    {
      id: 24,
      prompt: "How do you incorporate transaction costs into your research?",
      tags: ["Transaction Costs", "Research", "Costs"],
      starChecks: [
        "Cost models (spread, impact, commissions)",
        "Backtesting with costs",
        "Optimization with cost constraints",
        "Realistic cost assumptions",
      ],
    },
    {
      id: 25,
      prompt: "Describe your approach to stress-testing a strategy.",
      tags: ["Stress Testing", "Risk Management", "Research"],
      starChecks: [
        "Historical stress scenarios",
        "Monte Carlo stress tests",
        "Regime change scenarios",
        "Tail risk analysis",
      ],
    },
    {
      id: 26,
      prompt: "How would you research optimal execution algorithms for your strategy?",
      tags: ["Execution", "Research", "Algorithms"],
      starChecks: [
        "TWAP, VWAP, implementation shortfall",
        "Market impact models",
        "Optimal execution research",
        "Testing execution algorithms",
      ],
    },
    {
      id: 27,
      prompt: "What's your framework for thinking about strategy diversification?",
      tags: ["Diversification", "Portfolio", "Research"],
      starChecks: [
        "Correlation structure",
        "Risk contribution",
        "Alpha diversification",
        "Optimal number of strategies",
      ],
    },
    {
      id: 28,
      prompt: "How do you handle survivorship bias in historical data?",
      tags: ["Survivorship Bias", "Data Quality", "Research"],
      starChecks: [
        "Identifying survivorship bias",
        "Using point-in-time data",
        "Including delisted stocks",
        "Correcting for bias",
      ],
    },
    {
      id: 29,
      prompt: "Describe how you'd research the optimal rebalancing frequency.",
      tags: ["Rebalancing", "Research", "Optimization"],
      starChecks: [
        "Trade-off: alpha decay vs transaction costs",
        "Testing different frequencies",
        "Adaptive rebalancing",
        "Optimal frequency determination",
      ],
    },
    {
      id: 30,
      prompt: "How do you think about the explainability vs performance trade-off in ML models for trading?",
      tags: ["Explainability", "ML Models", "Trade-offs", "Research"],
      starChecks: [
        "When explainability matters",
        "Interpretable models vs black boxes",
        "Post-hoc explanation methods",
        "Balancing performance and interpretability",
      ],
    },
  ] as BehavioralQuestion[],
  'quant-models': [
    {
      id: 1,
      question: 'What is Brownian motion, and which of its properties are essential for financial modeling?',
      answer: 'Brownian motion (Wiener process) is a continuous-time stochastic process with: independent increments (future moves independent of past), normally distributed increments (ΔW ~ N(0, Δt)), zero mean (E[ΔW] = 0), and variance proportional to time (Var(ΔW) = Δt). Essential properties: Markov property (memoryless), martingale property (E[W(t)|W(s)] = W(s)), and continuous paths. Used to model asset price randomness.',
      hint: 'Brownian motion has independent, normally distributed increments with variance proportional to time',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 2,
      question: 'Why do we model prices with geometric Brownian motion instead of arithmetic Brownian motion?',
      answer: 'Geometric Brownian motion (GBM): dS = μS dt + σS dW ensures prices stay positive (S > 0 always), has percentage returns (dS/S is normally distributed), and matches empirical behavior (prices are multiplicative, not additive). Arithmetic: dS = μ dt + σ dW can go negative (unrealistic for prices), has absolute returns. GBM is standard for equity prices.',
      hint: 'Geometric Brownian motion ensures prices stay positive and models percentage returns',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 3,
      question: 'What assumptions of Black–Scholes are most violated in real markets?',
      answer: 'Most violated: constant volatility (volatility is stochastic, has smile/skew), continuous trading (no jumps, but markets have jumps), no transaction costs (real trading has costs), constant interest rates (rates are stochastic), and log-normal returns (returns have fat tails, skewness). Reality: volatility smiles, jumps, transaction costs, stochastic rates, and non-normal returns.',
      hint: 'Black-Scholes assumes constant volatility, continuous trading, no jumps, and log-normal returns - all violated in reality',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 4,
      question: 'Explain Ito\'s Lemma and give a financial intuition for it.',
      answer: 'Ito\'s Lemma: if f(S,t) is a function of a stochastic process S following dS = μ dt + σ dW, then df = (∂f/∂t + μ∂f/∂S + ½σ²∂²f/∂S²)dt + σ∂f/∂S dW. Financial intuition: derivative price depends on underlying (∂f/∂S), time decay (∂f/∂t), and convexity (½σ²∂²f/∂S² - the "gamma" term). The extra ½σ² term comes from stochastic calculus (not ordinary calculus). Essential for option pricing.',
      hint: 'Ito\'s Lemma accounts for the convexity term (gamma) that arises from stochastic calculus',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 5,
      question: 'What does it mean to change from the physical measure to the risk-neutral measure?',
      answer: 'Physical measure (P): real-world probabilities, uses real drift μ. Risk-neutral measure (Q): pricing probabilities, uses risk-free rate r as drift. Change: replace μ with r, adjust probabilities so discounted prices are martingales. Why: allows pricing derivatives using risk-free rate, eliminates need to estimate risk premium. Fundamental theorem: derivative price = E^Q[discounted payoff].',
      hint: 'Risk-neutral measure uses risk-free rate as drift and makes discounted prices martingales',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 6,
      question: 'Why does the implied volatility smile contradict Black–Scholes?',
      answer: 'Black-Scholes assumes constant volatility (same vol for all strikes/maturities). Smile: implied volatility varies by strike (higher vol for OTM puts/calls) and maturity (term structure). Contradiction: if BS were correct, all options would have same implied vol. Reality: market prices options with different vols, showing BS is wrong. Smile reflects: stochastic vol, jumps, and fat tails.',
      hint: 'The volatility smile shows that implied volatility varies by strike and maturity, contradicting constant volatility assumption',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 7,
      question: 'What problem does the local volatility model solve?',
      answer: 'Local volatility model: σ(S,t) is deterministic function of spot and time. Solves: fits all vanilla option prices exactly (can calibrate to smile), provides unique volatility surface, and allows pricing exotics consistently. Problem solved: how to price exotics when vanilla options show smile. Solution: use local vol surface calibrated to vanillas. Limitation: assumes deterministic vol (not stochastic).',
      hint: 'Local volatility model fits the volatility smile by making volatility a deterministic function of spot and time',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 8,
      question: 'Explain Dupire\'s local volatility formula and its main limitation.',
      answer: 'Dupire formula: σ_loc²(K,T) = 2(∂C/∂T + rK∂C/∂K) / (K²∂²C/∂K²). Gives local vol from call prices. Limitation: assumes deterministic volatility (vol depends only on S and t, not random), but real vol is stochastic. Problem: local vol predicts wrong forward smile dynamics (smile flattens too fast). Reality: stochastic vol models needed for forward smile.',
      hint: 'Dupire formula extracts local volatility from option prices, but assumes deterministic volatility',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 9,
      question: 'What motivates stochastic volatility models over local volatility?',
      answer: 'Stochastic volatility: vol is random process (dσ = ... dt + ... dW). Motivation: captures vol clustering (high vol periods), matches forward smile dynamics (smile doesn\'t flatten too fast), and models vol-of-vol risk. Local vol: deterministic, wrong forward smile. Stochastic vol: random, correct forward smile. Heston model is popular stochastic vol model.',
      hint: 'Stochastic volatility models capture random volatility dynamics and correct forward smile behavior',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 10,
      question: 'Write the Heston model and explain the role of correlation.',
      answer: 'Heston model: dS = rS dt + √V S dW₁, dV = κ(θ - V)dt + σ√V dW₂, where dW₁ dW₂ = ρ dt. Correlation ρ: links stock and vol moves. Negative ρ (leverage effect): stock down → vol up (typical for equities). Positive ρ: stock up → vol up. Zero ρ: independent. Correlation creates skew: negative ρ → left skew (OTM puts expensive).',
      hint: 'Heston model has two correlated Brownian motions - correlation creates volatility skew',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 11,
      question: 'What is the Feller condition and what happens if it is violated?',
      answer: 'Feller condition: 2κθ ≥ σ² (for Heston model). Ensures: volatility V stays positive (never hits zero). If violated: V can hit zero (becomes negative, then model breaks). Interpretation: mean reversion (κθ) must be strong enough relative to vol-of-vol (σ) to keep V positive. In practice: often violated, but model still used (V rarely hits zero in practice).',
      hint: 'Feller condition ensures volatility stays positive in the Heston model',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 12,
      question: 'Why do stochastic volatility models still struggle with short-dated smiles?',
      answer: 'Short-dated smiles: very steep, hard to fit. Problem: stochastic vol models smooth out smile (vol evolves continuously), but short-dated options need sharp moves (jumps). Solution: add jumps (jump-diffusion models). Reality: short-dated = jump risk dominates, long-dated = vol risk dominates. Pure stochastic vol: good for long-dated, struggles with short-dated.',
      hint: 'Short-dated smiles require jumps, which pure stochastic volatility models don\'t capture',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 13,
      question: 'What is rough volatility, and what empirical fact does it explain?',
      answer: 'Rough volatility: volatility has fractional Brownian motion with Hurst exponent H < 1/2 (anti-persistent). Explains: very steep short-dated smile (power-law decay, not exponential). Standard models: exponential decay. Rough vol: power-law decay (matches data). Key: vol is "rough" (less smooth than standard models predict). Recent research area.',
      hint: 'Rough volatility models use fractional Brownian motion to explain the steep short-dated volatility smile',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 14,
      question: 'Why are jumps needed in asset price models?',
      answer: 'Jumps needed because: markets have sudden moves (news, crashes), short-dated options show steep smiles (jump risk), and continuous models underestimate tail risk. Pure diffusion: smooth paths, can\'t capture crashes. Jump-diffusion: sudden moves, captures crashes and short-dated smile. Merton model: adds Poisson jumps to GBM.',
      hint: 'Jumps capture sudden market moves and explain the steep short-dated volatility smile',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 15,
      question: 'Compare Merton\'s jump–diffusion and pure Lévy models (e.g. VG or CGMY).',
      answer: 'Merton: GBM + Poisson jumps (finite activity, discrete jumps). VG/CGMY: pure Lévy (infinite activity, many small jumps). Merton: simpler, finite jumps. Lévy: more flexible, infinite small jumps. Both: capture fat tails and smiles. Merton: easier to calibrate. Lévy: better fit to data, more complex. Choice: depends on application and data fit.',
      hint: 'Merton has finite discrete jumps, while Lévy models have infinite small jumps',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 16,
      question: 'How do jump models affect short-maturity option prices?',
      answer: 'Jump models: increase short-maturity option prices (especially OTM), create steep smile (jump risk premium), and capture crash risk. Pure diffusion: smooth smile. Jump-diffusion: steep smile (matches data). Short-dated: jump risk dominates (sudden moves matter more). Long-dated: vol risk dominates (jumps average out).',
      hint: 'Jump models increase short-maturity option prices and create steep volatility smiles',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 17,
      question: 'Why is mean reversion essential in interest rate models?',
      answer: 'Mean reversion: rates tend to return to long-term mean. Essential because: rates are bounded (can\'t go to infinity), economic forces pull rates to equilibrium, and models need realistic long-term behavior. Without mean reversion: rates can explode or go negative (unrealistic). Vasicek, CIR, Hull-White: all have mean reversion.',
      hint: 'Mean reversion ensures interest rates stay bounded and return to long-term equilibrium',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 18,
      question: 'Compare Vasicek and CIR models. Why is CIR often preferred?',
      answer: 'Vasicek: dr = κ(θ - r)dt + σ dW (Gaussian, can go negative). CIR: dr = κ(θ - r)dt + σ√r dW (square-root, stays positive). CIR preferred: rates stay positive (realistic), volatility scales with rate level (higher rates = higher vol), and better empirical fit. Vasicek: simpler, but can go negative (unrealistic).',
      hint: 'CIR model ensures rates stay positive and has volatility that scales with the rate level',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 19,
      question: 'What is the Hull–White model and why is it popular in practice?',
      answer: 'Hull-White: dr = (θ(t) - ar)dt + σ dW (time-dependent mean reversion level). Popular because: fits initial yield curve exactly (θ(t) calibrated to market), mean reverting (realistic long-term), and analytically tractable (closed-form solutions). Used for: pricing interest rate derivatives, risk management. Industry standard for IR modeling.',
      hint: 'Hull-White model fits the initial yield curve exactly and is analytically tractable',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 20,
      question: 'What is adverse selection and how is it modeled mathematically?',
      answer: 'Adverse selection: informed traders trade against you (they know something you don\'t). Mathematical models: Glosten-Milgrom (bid-ask spread reflects information asymmetry), Kyle model (informed trader optimal strategy), and Avellaneda-Stoikov (optimal market making with adverse selection). Key: probability of informed trading (PIN) affects optimal quotes. Higher PIN = wider spreads.',
      hint: 'Adverse selection models incorporate the probability of informed trading to determine optimal market making quotes',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 21,
      question: 'Explain the Glosten–Milgrom or Kyle model in words.',
      answer: 'Glosten-Milgrom: market maker sets bid/ask, doesn\'t know if trader is informed. Informed trader: knows true value, trades when profitable. Uninformed: trades randomly. Market maker: updates beliefs from trades, widens spread when suspicious. Kyle model: informed trader chooses optimal trade size (balances profit vs price impact). Both: model information asymmetry and optimal strategies.',
      hint: 'These models analyze how market makers and informed traders behave under information asymmetry',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 22,
      question: 'What problem does the Avellaneda–Stoikov model solve?',
      answer: 'Avellaneda-Stoikov: optimal market making problem. Solves: how to quote bid/ask to maximize expected utility while managing inventory risk. Solution: optimal quotes depend on inventory (skew if imbalanced), time to expiration (wider near end), and risk aversion. Key: balances profit (spread) vs risk (inventory). Widely used in practice for algorithmic market making.',
      hint: 'Avellaneda-Stoikov solves the optimal market making problem with inventory risk management',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 23,
      question: 'How does inventory risk enter optimal market-making strategies?',
      answer: 'Inventory risk: holding imbalanced positions (long or short). Enters strategy: skew quotes (make long side cheaper to encourage sells), widen spreads (compensate for risk), and set position limits (stop if too imbalanced). Optimal quotes: depend on current inventory. More inventory = more risk = wider spreads, more skew. Goal: balance profit vs risk.',
      hint: 'Inventory risk causes market makers to skew quotes and widen spreads to manage position exposure',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 24,
      question: 'Why are Hawkes processes useful for modeling order flow?',
      answer: 'Hawkes processes: self-exciting point processes (events trigger more events). Useful because: order flow has clustering (orders trigger more orders), captures feedback (trades cause more trades), and models contagion (one market affects others). Applications: high-frequency trading, market impact, order flow prediction. Better than Poisson (which assumes independence).',
      hint: 'Hawkes processes model self-exciting order flow where events trigger more events',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 25,
      question: 'When would you prefer Monte Carlo over PDE methods (and vice versa)?',
      answer: 'Monte Carlo: prefer for high dimensions (many assets), path-dependent options (Asian, lookback), and complex payoffs. PDE: prefer for low dimensions (1-2 assets), early exercise (American options), and Greeks (sensitivities). Trade-off: MC = flexible but slow, PDE = fast but limited dimensions. Hybrid: use both depending on problem.',
      hint: 'Monte Carlo for high dimensions and path-dependence, PDE for low dimensions and early exercise',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 26,
      question: 'Why is Heston pricing often done using characteristic functions and FFT?',
      answer: 'Heston: no closed-form for option prices (stochastic vol). Characteristic function: closed-form for Heston (Fourier transform of density). FFT: fast numerical integration to compute option prices from characteristic function. Advantage: fast (O(N log N)), accurate, handles many strikes at once. Standard method: Heston characteristic function + FFT = efficient pricing.',
      hint: 'Characteristic functions and FFT provide fast, accurate pricing for stochastic volatility models',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 27,
      question: 'What are the main numerical challenges in calibrating volatility models?',
      answer: 'Challenges: high-dimensional optimization (many parameters), non-convex objective (multiple local minima), expensive pricing (each evaluation costs time), and overfitting (fits noise, not signal). Solutions: good initial guesses, regularization, efficient pricing methods (FFT, approximations), and out-of-sample validation. Calibration is art + science.',
      hint: 'Calibration faces challenges from high-dimensional optimization, non-convex objectives, and expensive pricing',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 28,
      question: 'Why can two models fit vanilla options equally well but hedge very differently?',
      answer: 'Different models: can fit same vanilla prices (same implied vols), but have different Greeks (deltas, gammas, vegas differ). Reason: models differ in dynamics (local vol vs stochastic vol), even if prices match. Hedging: depends on Greeks, not just prices. Local vol: wrong forward smile → wrong hedges. Stochastic vol: correct forward smile → better hedges.',
      hint: 'Models that fit vanilla prices equally can have different Greeks and thus different hedging behavior',
      difficulty: 'hard',
      targetTime: 90,
    },
    {
      id: 29,
      question: 'How do model assumptions typically break during market stress?',
      answer: 'During stress: correlations spike (diversification fails), volatility explodes (models underestimate), jumps occur (continuous models break), liquidity dries up (models assume liquid), and fat tails appear (normal distributions fail). Models: calibrated to normal times, break in stress. Solution: stress testing, scenario analysis, and conservative assumptions.',
      hint: 'Model assumptions break during stress when correlations spike, volatility explodes, and jumps occur',
      difficulty: 'medium',
      targetTime: 75,
    },
    {
      id: 30,
      question: 'If you were running a market-making book, how would you decide which model matters most?',
      answer: 'Decision factors: what you\'re trading (vanillas vs exotics), time horizon (short vs long), and risk tolerance. Vanillas: simple model (local vol) may suffice. Exotics: need stochastic vol/jumps. Short-dated: jumps matter. Long-dated: vol dynamics matter. Risk: simpler = easier to understand, complex = better fit but harder. Practical: use simplest model that captures key risks.',
      hint: 'Choose models based on what you\'re trading, time horizon, and risk tolerance - simplest that captures key risks',
      difficulty: 'hard',
      targetTime: 90,
    },
  ] as TradingQuestion[],
}

export const quantCategoryLabels: Record<string, string> = {
  'mental-calculations': 'Mental Calculations',
  'probability-exercises': 'Probability Exercises',
  'brainteasers': 'Brainteasers',
  'coding-project': 'Coding Project',
  'statistics-ml': 'Statistics & ML',
  'trading-intuition': 'Trading Intuition',
  'research-discussion': 'Research Discussion',
  'quant-models': 'Quant Models',
}

